{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn import model_selection as sk\n",
    "import os, re, h5py, shutil\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.error import HTTPError\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "df_inc = pd.read_csv('../../Jaffedbase_labels_FearIncluded.csv', sep=' ')\n",
    "df_exc = pd.read_csv('../../Jaffedbase_labels_FearExcluded.csv', sep=' ')\n",
    "df_inc['jpeg_names'] = df_inc.PIC.values\n",
    "lst = df_inc.jpeg_names\n",
    "lst[:] += '.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>HAP</th>\n",
       "      <th>SAD</th>\n",
       "      <th>SUR</th>\n",
       "      <th>ANG</th>\n",
       "      <th>DIS</th>\n",
       "      <th>FEA</th>\n",
       "      <th>PIC</th>\n",
       "      <th>jpeg_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.87</td>\n",
       "      <td>2.52</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.97</td>\n",
       "      <td>2.06</td>\n",
       "      <td>KM-NE1</td>\n",
       "      <td>KM-NE1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.87</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.77</td>\n",
       "      <td>KM-NE2</td>\n",
       "      <td>KM-NE2.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.73</td>\n",
       "      <td>1.53</td>\n",
       "      <td>KM-NE3</td>\n",
       "      <td>KM-NE3.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.90</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.10</td>\n",
       "      <td>KM-HA1</td>\n",
       "      <td>KM-HA1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4.87</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.07</td>\n",
       "      <td>KM-HA2</td>\n",
       "      <td>KM-HA2.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>4.61</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.19</td>\n",
       "      <td>KM-HA3</td>\n",
       "      <td>KM-HA3.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.06</td>\n",
       "      <td>KM-HA4</td>\n",
       "      <td>KM-HA4.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>4.65</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>KM-HA5</td>\n",
       "      <td>KM-HA5.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.42</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2.39</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.03</td>\n",
       "      <td>KM-SA1</td>\n",
       "      <td>KM-SA1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.23</td>\n",
       "      <td>4.39</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.61</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.71</td>\n",
       "      <td>KM-SA2</td>\n",
       "      <td>KM-SA2.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1.32</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.77</td>\n",
       "      <td>3.19</td>\n",
       "      <td>KM-SA3</td>\n",
       "      <td>KM-SA3.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1.26</td>\n",
       "      <td>4.29</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>2.94</td>\n",
       "      <td>KM-SA4</td>\n",
       "      <td>KM-SA4.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1.35</td>\n",
       "      <td>4.13</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.81</td>\n",
       "      <td>3.10</td>\n",
       "      <td>KM-SA5</td>\n",
       "      <td>KM-SA5.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>2.13</td>\n",
       "      <td>1.55</td>\n",
       "      <td>4.97</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.10</td>\n",
       "      <td>KM-SU1</td>\n",
       "      <td>KM-SU1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1.90</td>\n",
       "      <td>4.97</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.81</td>\n",
       "      <td>3.10</td>\n",
       "      <td>KM-SU2</td>\n",
       "      <td>KM-SU2.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1.84</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.32</td>\n",
       "      <td>KM-SU3</td>\n",
       "      <td>KM-SU3.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.57</td>\n",
       "      <td>4.58</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.68</td>\n",
       "      <td>KM-AN1</td>\n",
       "      <td>KM-AN1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1.68</td>\n",
       "      <td>4.06</td>\n",
       "      <td>3.87</td>\n",
       "      <td>1.90</td>\n",
       "      <td>KM-AN2</td>\n",
       "      <td>KM-AN2.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1.42</td>\n",
       "      <td>2.13</td>\n",
       "      <td>1.55</td>\n",
       "      <td>4.16</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.77</td>\n",
       "      <td>KM-AN3</td>\n",
       "      <td>KM-AN3.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1.26</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.81</td>\n",
       "      <td>3.52</td>\n",
       "      <td>4.71</td>\n",
       "      <td>2.26</td>\n",
       "      <td>KM-DI1</td>\n",
       "      <td>KM-DI1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2.13</td>\n",
       "      <td>1.74</td>\n",
       "      <td>3.16</td>\n",
       "      <td>4.32</td>\n",
       "      <td>2.13</td>\n",
       "      <td>KM-DI2</td>\n",
       "      <td>KM-DI2.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.94</td>\n",
       "      <td>3.61</td>\n",
       "      <td>4.58</td>\n",
       "      <td>1.94</td>\n",
       "      <td>KM-DI3</td>\n",
       "      <td>KM-DI3.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>2.52</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.61</td>\n",
       "      <td>1.97</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.87</td>\n",
       "      <td>KM-FE1</td>\n",
       "      <td>KM-FE1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2.83</td>\n",
       "      <td>3.77</td>\n",
       "      <td>3.80</td>\n",
       "      <td>KM-FE2</td>\n",
       "      <td>KM-FE2.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.84</td>\n",
       "      <td>3.61</td>\n",
       "      <td>2.90</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.19</td>\n",
       "      <td>KM-FE3</td>\n",
       "      <td>KM-FE3.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>3.03</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.87</td>\n",
       "      <td>KA-NE1</td>\n",
       "      <td>KA-NE1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2.13</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.87</td>\n",
       "      <td>KA-NE2</td>\n",
       "      <td>KA-NE2.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>3.06</td>\n",
       "      <td>1.84</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.84</td>\n",
       "      <td>KA-NE3</td>\n",
       "      <td>KA-NE3.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>4.39</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.26</td>\n",
       "      <td>KA-HA1</td>\n",
       "      <td>KA-HA1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>4.77</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.45</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.23</td>\n",
       "      <td>KA-HA2</td>\n",
       "      <td>KA-HA2.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>190</td>\n",
       "      <td>1.42</td>\n",
       "      <td>3.19</td>\n",
       "      <td>1.77</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.58</td>\n",
       "      <td>TM-AN1</td>\n",
       "      <td>TM-AN1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>191</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2.58</td>\n",
       "      <td>1.74</td>\n",
       "      <td>4.13</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1.94</td>\n",
       "      <td>TM-AN2</td>\n",
       "      <td>TM-AN2.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>192</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1.77</td>\n",
       "      <td>4.16</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.94</td>\n",
       "      <td>TM-AN3</td>\n",
       "      <td>TM-AN3.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>193</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.19</td>\n",
       "      <td>3.16</td>\n",
       "      <td>4.81</td>\n",
       "      <td>2.39</td>\n",
       "      <td>TM-DI1</td>\n",
       "      <td>TM-DI1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>194</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.32</td>\n",
       "      <td>3.23</td>\n",
       "      <td>4.65</td>\n",
       "      <td>2.32</td>\n",
       "      <td>TM-DI2</td>\n",
       "      <td>TM-DI2.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>195</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.39</td>\n",
       "      <td>1.90</td>\n",
       "      <td>3.10</td>\n",
       "      <td>4.55</td>\n",
       "      <td>2.87</td>\n",
       "      <td>TM-DI3</td>\n",
       "      <td>TM-DI3.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196</td>\n",
       "      <td>1.42</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.29</td>\n",
       "      <td>2.52</td>\n",
       "      <td>4.16</td>\n",
       "      <td>3.45</td>\n",
       "      <td>TM-FE1</td>\n",
       "      <td>TM-FE1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.77</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2.32</td>\n",
       "      <td>4.39</td>\n",
       "      <td>3.10</td>\n",
       "      <td>TM-FE2</td>\n",
       "      <td>TM-FE2.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.35</td>\n",
       "      <td>2.39</td>\n",
       "      <td>4.19</td>\n",
       "      <td>3.42</td>\n",
       "      <td>TM-FE3</td>\n",
       "      <td>TM-FE3.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.19</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.68</td>\n",
       "      <td>NA-NE1</td>\n",
       "      <td>NA-NE1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>2.84</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.03</td>\n",
       "      <td>NA-NE2</td>\n",
       "      <td>NA-NE2.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>201</td>\n",
       "      <td>2.77</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.84</td>\n",
       "      <td>2.32</td>\n",
       "      <td>2.23</td>\n",
       "      <td>2.61</td>\n",
       "      <td>NA-NE3</td>\n",
       "      <td>NA-NE3.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>202</td>\n",
       "      <td>4.77</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.16</td>\n",
       "      <td>NA-HA1</td>\n",
       "      <td>NA-HA1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>203</td>\n",
       "      <td>4.65</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.10</td>\n",
       "      <td>NA-HA2</td>\n",
       "      <td>NA-HA2.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>204</td>\n",
       "      <td>4.48</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.35</td>\n",
       "      <td>NA-HA3</td>\n",
       "      <td>NA-HA3.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>205</td>\n",
       "      <td>1.52</td>\n",
       "      <td>4.03</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.03</td>\n",
       "      <td>2.94</td>\n",
       "      <td>NA-SA1</td>\n",
       "      <td>NA-SA1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>206</td>\n",
       "      <td>1.29</td>\n",
       "      <td>3.74</td>\n",
       "      <td>1.39</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2.29</td>\n",
       "      <td>NA-SA2</td>\n",
       "      <td>NA-SA2.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>207</td>\n",
       "      <td>1.71</td>\n",
       "      <td>3.16</td>\n",
       "      <td>1.84</td>\n",
       "      <td>3.48</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.58</td>\n",
       "      <td>NA-SA3</td>\n",
       "      <td>NA-SA3.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>208</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.48</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.39</td>\n",
       "      <td>NA-SU1</td>\n",
       "      <td>NA-SU1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>209</td>\n",
       "      <td>2.68</td>\n",
       "      <td>1.45</td>\n",
       "      <td>4.52</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.03</td>\n",
       "      <td>2.00</td>\n",
       "      <td>NA-SU2</td>\n",
       "      <td>NA-SU2.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>210</td>\n",
       "      <td>2.39</td>\n",
       "      <td>1.55</td>\n",
       "      <td>4.48</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.81</td>\n",
       "      <td>NA-SU3</td>\n",
       "      <td>NA-SU3.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>211</td>\n",
       "      <td>1.19</td>\n",
       "      <td>2.55</td>\n",
       "      <td>1.61</td>\n",
       "      <td>4.45</td>\n",
       "      <td>3.65</td>\n",
       "      <td>1.71</td>\n",
       "      <td>NA-AN1</td>\n",
       "      <td>NA-AN1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>212</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.39</td>\n",
       "      <td>1.67</td>\n",
       "      <td>4.52</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.71</td>\n",
       "      <td>NA-AN2</td>\n",
       "      <td>NA-AN2.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>213</td>\n",
       "      <td>1.32</td>\n",
       "      <td>2.61</td>\n",
       "      <td>1.61</td>\n",
       "      <td>4.48</td>\n",
       "      <td>3.23</td>\n",
       "      <td>1.94</td>\n",
       "      <td>NA-AN3</td>\n",
       "      <td>NA-AN3.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>214</td>\n",
       "      <td>1.32</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1.58</td>\n",
       "      <td>3.65</td>\n",
       "      <td>4.29</td>\n",
       "      <td>1.87</td>\n",
       "      <td>NA-DI1</td>\n",
       "      <td>NA-DI1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>215</td>\n",
       "      <td>1.45</td>\n",
       "      <td>3.19</td>\n",
       "      <td>1.81</td>\n",
       "      <td>3.16</td>\n",
       "      <td>4.19</td>\n",
       "      <td>2.77</td>\n",
       "      <td>NA-DI2</td>\n",
       "      <td>NA-DI2.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>216</td>\n",
       "      <td>1.43</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1.77</td>\n",
       "      <td>4.33</td>\n",
       "      <td>3.87</td>\n",
       "      <td>2.10</td>\n",
       "      <td>NA-DI3</td>\n",
       "      <td>NA-DI3.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>217</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.68</td>\n",
       "      <td>4.10</td>\n",
       "      <td>3.16</td>\n",
       "      <td>3.81</td>\n",
       "      <td>3.90</td>\n",
       "      <td>NA-FE1</td>\n",
       "      <td>NA-FE1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>218</td>\n",
       "      <td>1.68</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.74</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.87</td>\n",
       "      <td>NA-FE2</td>\n",
       "      <td>NA-FE2.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>219</td>\n",
       "      <td>1.48</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>2.71</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.74</td>\n",
       "      <td>NA-FE3</td>\n",
       "      <td>NA-FE3.jpeg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #   HAP   SAD   SUR   ANG   DIS   FEA     PIC   jpeg_names\n",
       "0      1  2.87  2.52  2.10  1.97  1.97  2.06  KM-NE1  KM-NE1.jpeg\n",
       "1      2  2.87  2.42  1.58  1.84  1.77  1.77  KM-NE2  KM-NE2.jpeg\n",
       "2      3  2.50  2.10  1.70  1.50  1.73  1.53  KM-NE3  KM-NE3.jpeg\n",
       "3      4  4.90  1.13  1.26  1.10  1.03  1.10  KM-HA1  KM-HA1.jpeg\n",
       "4      5  4.87  1.20  1.43  1.03  1.07  1.07  KM-HA2  KM-HA2.jpeg\n",
       "5      6  4.61  1.32  1.39  1.23  1.10  1.19  KM-HA3  KM-HA3.jpeg\n",
       "6      7  5.00  1.13  1.26  1.10  1.10  1.06  KM-HA4  KM-HA4.jpeg\n",
       "7      8  4.65  1.29  1.39  1.23  1.16  1.16  KM-HA5  KM-HA5.jpeg\n",
       "8      9  1.42  4.00  1.55  2.39  3.26  3.03  KM-SA1  KM-SA1.jpeg\n",
       "9     10  1.23  4.39  1.45  2.61  3.19  2.71  KM-SA2  KM-SA2.jpeg\n",
       "10    11  1.32  4.00  1.87  2.60  3.77  3.19  KM-SA3  KM-SA3.jpeg\n",
       "11    12  1.26  4.29  1.58  2.26  3.39  2.94  KM-SA4  KM-SA4.jpeg\n",
       "12    13  1.35  4.13  1.61  2.10  3.81  3.10  KM-SA5  KM-SA5.jpeg\n",
       "13    14  2.13  1.55  4.97  1.65  1.45  2.10  KM-SU1  KM-SU1.jpeg\n",
       "14    15  2.16  1.90  4.97  1.74  1.81  3.10  KM-SU2  KM-SU2.jpeg\n",
       "15    16  2.16  1.84  4.94  1.71  1.65  2.32  KM-SU3  KM-SU3.jpeg\n",
       "16    17  1.39  2.03  1.57  4.58  3.77  1.68  KM-AN1  KM-AN1.jpeg\n",
       "17    18  1.45  2.84  1.68  4.06  3.87  1.90  KM-AN2  KM-AN2.jpeg\n",
       "18    19  1.42  2.13  1.55  4.16  3.58  1.77  KM-AN3  KM-AN3.jpeg\n",
       "19    20  1.26  2.10  1.81  3.52  4.71  2.26  KM-DI1  KM-DI1.jpeg\n",
       "20    21  1.55  2.13  1.74  3.16  4.32  2.13  KM-DI2  KM-DI2.jpeg\n",
       "21    22  1.39  1.87  1.94  3.61  4.58  1.94  KM-DI3  KM-DI3.jpeg\n",
       "22    23  2.52  2.58  2.61  1.97  2.90  2.87  KM-FE1  KM-FE1.jpeg\n",
       "23    24  1.50  2.97  3.67  2.83  3.77  3.80  KM-FE2  KM-FE2.jpeg\n",
       "24    25  1.68  2.84  3.61  2.90  3.84  3.19  KM-FE3  KM-FE3.jpeg\n",
       "25    26  3.03  2.16  2.06  1.94  1.84  1.87  KA-NE1  KA-NE1.jpeg\n",
       "26    27  2.84  1.94  2.13  1.77  1.68  1.87  KA-NE2  KA-NE2.jpeg\n",
       "27    28  3.06  1.84  2.29  1.77  1.71  1.84  KA-NE3  KA-NE3.jpeg\n",
       "28    29  4.39  1.35  2.29  1.16  1.23  1.26  KA-HA1  KA-HA1.jpeg\n",
       "29    30  4.77  1.29  2.45  1.26  1.23  1.23  KA-HA2  KA-HA2.jpeg\n",
       "..   ...   ...   ...   ...   ...   ...   ...     ...          ...\n",
       "189  190  1.42  3.19  1.77  4.06  4.00  2.58  TM-AN1  TM-AN1.jpeg\n",
       "190  191  1.39  2.58  1.74  4.13  3.48  1.94  TM-AN2  TM-AN2.jpeg\n",
       "191  192  1.55  2.16  1.77  4.16  3.32  1.94  TM-AN3  TM-AN3.jpeg\n",
       "192  193  1.35  1.81  2.19  3.16  4.81  2.39  TM-DI1  TM-DI1.jpeg\n",
       "193  194  1.55  2.39  2.32  3.23  4.65  2.32  TM-DI2  TM-DI2.jpeg\n",
       "194  195  1.35  2.39  1.90  3.10  4.55  2.87  TM-DI3  TM-DI3.jpeg\n",
       "195  196  1.42  3.06  3.29  2.52  4.16  3.45  TM-FE1  TM-FE1.jpeg\n",
       "196  197  1.45  2.77  3.13  2.32  4.39  3.10  TM-FE2  TM-FE2.jpeg\n",
       "197  198  1.35  3.06  3.35  2.39  4.19  3.42  TM-FE3  TM-FE3.jpeg\n",
       "198  199  2.68  2.10  1.61  2.19  2.03  1.68  NA-NE1  NA-NE1.jpeg\n",
       "199  200  2.84  2.29  1.87  2.65  2.45  2.03  NA-NE2  NA-NE2.jpeg\n",
       "200  201  2.77  2.00  1.84  2.32  2.23  2.61  NA-NE3  NA-NE3.jpeg\n",
       "201  202  4.77  1.35  1.42  1.13  1.13  1.16  NA-HA1  NA-HA1.jpeg\n",
       "202  203  4.65  1.47  1.29  1.23  1.32  1.10  NA-HA2  NA-HA2.jpeg\n",
       "203  204  4.48  1.42  1.48  1.32  1.55  1.35  NA-HA3  NA-HA3.jpeg\n",
       "204  205  1.52  4.03  1.77  2.65  3.03  2.94  NA-SA1  NA-SA1.jpeg\n",
       "205  206  1.29  3.74  1.39  3.00  3.23  2.29  NA-SA2  NA-SA2.jpeg\n",
       "206  207  1.71  3.16  1.84  3.48  3.19  2.58  NA-SA3  NA-SA3.jpeg\n",
       "207  208  4.32  1.48  3.32  1.35  1.39  1.39  NA-SU1  NA-SU1.jpeg\n",
       "208  209  2.68  1.45  4.52  1.90  2.03  2.00  NA-SU2  NA-SU2.jpeg\n",
       "209  210  2.39  1.55  4.48  1.97  1.84  1.81  NA-SU3  NA-SU3.jpeg\n",
       "210  211  1.19  2.55  1.61  4.45  3.65  1.71  NA-AN1  NA-AN1.jpeg\n",
       "211  212  1.45  2.39  1.67  4.52  3.32  1.71  NA-AN2  NA-AN2.jpeg\n",
       "212  213  1.32  2.61  1.61  4.48  3.23  1.94  NA-AN3  NA-AN3.jpeg\n",
       "213  214  1.32  3.03  1.58  3.65  4.29  1.87  NA-DI1  NA-DI1.jpeg\n",
       "214  215  1.45  3.19  1.81  3.16  4.19  2.77  NA-DI2  NA-DI2.jpeg\n",
       "215  216  1.43  2.87  1.77  4.33  3.87  2.10  NA-DI3  NA-DI3.jpeg\n",
       "216  217  1.61  2.68  4.10  3.16  3.81  3.90  NA-FE1  NA-FE1.jpeg\n",
       "217  218  1.68  3.10  3.74  3.19  3.58  3.87  NA-FE2  NA-FE2.jpeg\n",
       "218  219  1.48  3.26  3.39  2.71  3.06  3.74  NA-FE3  NA-FE3.jpeg\n",
       "\n",
       "[219 rows x 9 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = sklearn.model_selection.KFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_folds():\n",
    "    os.mkdir('train')\n",
    "    os.mkdir('train/pos')\n",
    "    os.mkdir('train/neg')\n",
    "    os.mkdir('valid')\n",
    "    os.mkdir('valid/pos')\n",
    "    os.mkdir('valid/neg')\n",
    "    \n",
    "folds = []\n",
    "for fold_idx, split in enumerate(folder.split(X=df_inc.index.values)):\n",
    "    folds.append(split)\n",
    "\n",
    "def run_k_fold(k):\n",
    "    fold = folds[k]\n",
    "    train_df = df_inc.loc[fold[0]]\n",
    "    train_pos = train_df.loc[train_df.HAP.map(lambda x : True if x > 2.5 else False)]\n",
    "    train_neg = train_df.loc[train_df.HAP.map(lambda x : True if x <= 2.5 else False)]\n",
    "    valid_df = df_inc.loc[fold[1]]\n",
    "    valid_pos = valid_df.loc[valid_df.HAP.map(lambda x : True if x > 2.5 else False)]\n",
    "    valid_neg = valid_df.loc[valid_df.HAP.map(lambda x : True if x <= 2.5 else False)]\n",
    "    for member in train_pos['jpeg_names'].values:\n",
    "        os.link(member, os.path.join(os.path.abspath('train/pos'), member))\n",
    "    for member in train_neg['jpeg_names'].values:\n",
    "        os.link(member, os.path.join(os.path.abspath('train/neg'), member))\n",
    "    for member in valid_pos['jpeg_names'].values:\n",
    "        os.link(member, os.path.join(os.path.abspath('valid/pos'), member))\n",
    "    for member in valid_neg['jpeg_names'].values:\n",
    "        os.link(member, os.path.join(os.path.abspath('valid/neg'), member))\n",
    "        \n",
    "def clean_up_folds():\n",
    "    def clean_up(folder):\n",
    "        for the_file in os.listdir(folder):\n",
    "            file_path = os.path.join(folder, the_file)\n",
    "            try:\n",
    "                if os.path.isfile(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    clean_up('train')\n",
    "    os.rmdir('train')\n",
    "    clean_up('valid')\n",
    "    os.rmdir('valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_clean_up(df, directory):\n",
    "    lst = df['jpeg_names']\n",
    "    for row, name in enumerate(lst):\n",
    "        if name not in os.listdir(directory):\n",
    "            print(name)\n",
    "            df.drop(row, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 9)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inc.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f569279be80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_inc.HAP.hist(bins=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    212.000000\n",
       "mean       2.199387\n",
       "std        1.089119\n",
       "min        1.100000\n",
       "25%        1.390000\n",
       "50%        1.680000\n",
       "75%        2.732500\n",
       "max        5.000000\n",
       "Name: HAP, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inc.HAP.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KM-HA5.jpeg\n",
      "KM-SA4.jpeg\n",
      "KM-DI2.jpeg\n",
      "YN-HA2.jpeg\n",
      "KR-HA3.jpeg\n",
      "NM-DI2.jpeg\n",
      "TM-HA4.jpeg\n"
     ]
    }
   ],
   "source": [
    "df_clean_up(df_inc, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:15: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:18: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    }
   ],
   "source": [
    "clean_up_folds()\n",
    "setup_folds()\n",
    "run_k_fold(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212, 9)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inc.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 141 images belonging to 2 classes.\n",
      "Found 71 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_feed = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=20, width_shift_range=0.2,\n",
    "    height_shift_range=0.2, preprocessing_function=tf.keras.applications.xception.preprocess_input)\n",
    "train_iter = train_feed.flow_from_directory(\n",
    "    './train/', target_size=(299, 299), follow_links=True, class_mode='binary')\n",
    "valid_feed = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=0, width_shift_range=0,\n",
    "    height_shift_range=0, preprocessing_function=tf.keras.applications.xception.preprocess_input)\n",
    "valid_iter = valid_feed.flow_from_directory(\n",
    "    './valid/', target_size=(299, 299), follow_links=True, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_all_to_jpeg(directory):\n",
    "#     base = directory\n",
    "#     for file in os.listdir(directory):\n",
    "#         if file[-3:]=='jpg':\n",
    "#             os.rename(os.path.join(directory, file), os.path.join(directory, file[0:2]+\"-\"+file[3:6]+'.jpeg'))\n",
    "#             #print(file)\n",
    "#             #print(file[0:2]+\"-\"+file[3:6]+'.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_all_to_jpeg(os.path.abspath('./'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcpt_model = tf.keras.applications.Xception(include_top=False, weights='imagenet', input_shape=(299, 299, 3), \n",
    "                                              classes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right, so, we have the layers we add to map from the 2D output of xception. \n",
    "In TF, you work with graphs. Ok... so there is some confusing syntax here. `x` is a tensor. With TF (or Keras) you apply tensor to a layer with this wierd `()` syntax. It is because of the graph computational structure of TF, but don't worry about it. In short, lines 2-5 take the output of the line before it, and apply it to a new tensor operation.\n",
    "\n",
    "Now, lines 5-7 have a bunch of the hyper-parameters that the final layer needs. Just know that I believe that these are the best attributes based on reading a variety of NN papers for a BINARY classfier. For a binary classifier, we only have 1 output neuron, not two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xcpt_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(682, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(rate=0.3)(x)\n",
    "predictions = tf.keras.layers.Dense(1, 'sigmoid', bias_initializer='Zeros', \n",
    "                          kernel_initializer=tf.keras.initializers.glorot_uniform(),\n",
    "                          trainable=True, use_bias=True, name='predictions')(x)\n",
    "CNN = tf.keras.models.Model(inputs=xcpt_model.inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in CNN.layers[:len(xcpt_model.layers)]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN.compile(loss = tf.keras.losses.binary_crossentropy, \n",
    "                    optimizer = tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9),\n",
    "                    metrics=[\"acc\", tf.keras.metrics.mean_squared_logarithmic_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_weights_path = '/home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5'\n",
    "callbacks_list = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(top_weights_path, monitor='acc',\n",
    "                                       verbose=1, save_best_only=True),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='acc', patience=10, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 299, 299, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)            (None, 149, 149, 32)  864         input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormalizat (None, 149, 149, 32)  128         block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)    (None, 149, 149, 32)  0           block1_conv1_bn[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)            (None, 147, 147, 64)  18432       block1_conv1_act[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormalizat (None, 147, 147, 64)  256         block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)    (None, 147, 147, 64)  0           block1_conv2_bn[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2D (None, 147, 147, 128) 8768        block1_conv2_act[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormali (None, 147, 147, 128) 512         block2_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation) (None, 147, 147, 128) 0           block2_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2D (None, 147, 147, 128) 17536       block2_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormali (None, 147, 147, 128) 512         block2_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 74, 74, 128)   8192        block1_conv2_act[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 74, 74, 128)   0           block2_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 74, 74, 128)   512         conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_13 (Add)                     (None, 74, 74, 128)   0           block2_pool[0][0]                \n",
      "                                                                   batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation) (None, 74, 74, 128)   0           add_13[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2D (None, 74, 74, 256)   33920       block3_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormali (None, 74, 74, 256)   1024        block3_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation) (None, 74, 74, 256)   0           block3_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2D (None, 74, 74, 256)   67840       block3_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormali (None, 74, 74, 256)   1024        block3_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 37, 37, 256)   32768       add_13[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 37, 37, 256)   0           block3_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 37, 37, 256)   1024        conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_14 (Add)                     (None, 37, 37, 256)   0           block3_pool[0][0]                \n",
      "                                                                   batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation) (None, 37, 37, 256)   0           add_14[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2D (None, 37, 37, 728)   188672      block4_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormali (None, 37, 37, 728)   2912        block4_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation) (None, 37, 37, 728)   0           block4_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2D (None, 37, 37, 728)   536536      block4_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormali (None, 37, 37, 728)   2912        block4_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 19, 19, 728)   186368      add_14[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 19, 19, 728)   0           block4_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 19, 19, 728)   2912        conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_15 (Add)                     (None, 19, 19, 728)   0           block4_pool[0][0]                \n",
      "                                                                   batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation) (None, 19, 19, 728)   0           add_15[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2D (None, 19, 19, 728)   536536      block5_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormali (None, 19, 19, 728)   2912        block5_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation) (None, 19, 19, 728)   0           block5_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2D (None, 19, 19, 728)   536536      block5_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormali (None, 19, 19, 728)   2912        block5_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation) (None, 19, 19, 728)   0           block5_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2D (None, 19, 19, 728)   536536      block5_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormali (None, 19, 19, 728)   2912        block5_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_16 (Add)                     (None, 19, 19, 728)   0           block5_sepconv3_bn[0][0]         \n",
      "                                                                   add_15[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation) (None, 19, 19, 728)   0           add_16[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2D (None, 19, 19, 728)   536536      block6_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormali (None, 19, 19, 728)   2912        block6_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation) (None, 19, 19, 728)   0           block6_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2D (None, 19, 19, 728)   536536      block6_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormali (None, 19, 19, 728)   2912        block6_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation) (None, 19, 19, 728)   0           block6_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2D (None, 19, 19, 728)   536536      block6_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormali (None, 19, 19, 728)   2912        block6_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_17 (Add)                     (None, 19, 19, 728)   0           block6_sepconv3_bn[0][0]         \n",
      "                                                                   add_16[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation) (None, 19, 19, 728)   0           add_17[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2D (None, 19, 19, 728)   536536      block7_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormali (None, 19, 19, 728)   2912        block7_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation) (None, 19, 19, 728)   0           block7_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2D (None, 19, 19, 728)   536536      block7_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormali (None, 19, 19, 728)   2912        block7_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation) (None, 19, 19, 728)   0           block7_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2D (None, 19, 19, 728)   536536      block7_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormali (None, 19, 19, 728)   2912        block7_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_18 (Add)                     (None, 19, 19, 728)   0           block7_sepconv3_bn[0][0]         \n",
      "                                                                   add_17[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation) (None, 19, 19, 728)   0           add_18[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2D (None, 19, 19, 728)   536536      block8_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormali (None, 19, 19, 728)   2912        block8_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation) (None, 19, 19, 728)   0           block8_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2D (None, 19, 19, 728)   536536      block8_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormali (None, 19, 19, 728)   2912        block8_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation) (None, 19, 19, 728)   0           block8_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2D (None, 19, 19, 728)   536536      block8_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormali (None, 19, 19, 728)   2912        block8_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_19 (Add)                     (None, 19, 19, 728)   0           block8_sepconv3_bn[0][0]         \n",
      "                                                                   add_18[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation) (None, 19, 19, 728)   0           add_19[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2D (None, 19, 19, 728)   536536      block9_sepconv1_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormali (None, 19, 19, 728)   2912        block9_sepconv1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation) (None, 19, 19, 728)   0           block9_sepconv1_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2D (None, 19, 19, 728)   536536      block9_sepconv2_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormali (None, 19, 19, 728)   2912        block9_sepconv2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation) (None, 19, 19, 728)   0           block9_sepconv2_bn[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2D (None, 19, 19, 728)   536536      block9_sepconv3_act[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormali (None, 19, 19, 728)   2912        block9_sepconv3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "add_20 (Add)                     (None, 19, 19, 728)   0           block9_sepconv3_bn[0][0]         \n",
      "                                                                   add_19[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activation (None, 19, 19, 728)   0           add_20[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv2 (None, 19, 19, 728)   536536      block10_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNormal (None, 19, 19, 728)   2912        block10_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activation (None, 19, 19, 728)   0           block10_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv2 (None, 19, 19, 728)   536536      block10_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNormal (None, 19, 19, 728)   2912        block10_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activation (None, 19, 19, 728)   0           block10_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv2 (None, 19, 19, 728)   536536      block10_sepconv3_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNormal (None, 19, 19, 728)   2912        block10_sepconv3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_21 (Add)                     (None, 19, 19, 728)   0           block10_sepconv3_bn[0][0]        \n",
      "                                                                   add_20[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activation (None, 19, 19, 728)   0           add_21[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv2 (None, 19, 19, 728)   536536      block11_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNormal (None, 19, 19, 728)   2912        block11_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activation (None, 19, 19, 728)   0           block11_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv2 (None, 19, 19, 728)   536536      block11_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNormal (None, 19, 19, 728)   2912        block11_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activation (None, 19, 19, 728)   0           block11_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv2 (None, 19, 19, 728)   536536      block11_sepconv3_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNormal (None, 19, 19, 728)   2912        block11_sepconv3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_22 (Add)                     (None, 19, 19, 728)   0           block11_sepconv3_bn[0][0]        \n",
      "                                                                   add_21[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activation (None, 19, 19, 728)   0           add_22[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv2 (None, 19, 19, 728)   536536      block12_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNormal (None, 19, 19, 728)   2912        block12_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activation (None, 19, 19, 728)   0           block12_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv2 (None, 19, 19, 728)   536536      block12_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNormal (None, 19, 19, 728)   2912        block12_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activation (None, 19, 19, 728)   0           block12_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv2 (None, 19, 19, 728)   536536      block12_sepconv3_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNormal (None, 19, 19, 728)   2912        block12_sepconv3[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_23 (Add)                     (None, 19, 19, 728)   0           block12_sepconv3_bn[0][0]        \n",
      "                                                                   add_22[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activation (None, 19, 19, 728)   0           add_23[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv2 (None, 19, 19, 728)   536536      block13_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNormal (None, 19, 19, 728)   2912        block13_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activation (None, 19, 19, 728)   0           block13_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv2 (None, 19, 19, 1024)  752024      block13_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNormal (None, 19, 19, 1024)  4096        block13_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 10, 10, 1024)  745472      add_23[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)      (None, 10, 10, 1024)  0           block13_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 10, 10, 1024)  4096        conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_24 (Add)                     (None, 10, 10, 1024)  0           block13_pool[0][0]               \n",
      "                                                                   batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv2 (None, 10, 10, 1536)  1582080     add_24[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNormal (None, 10, 10, 1536)  6144        block14_sepconv1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activation (None, 10, 10, 1536)  0           block14_sepconv1_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv2 (None, 10, 10, 2048)  3159552     block14_sepconv1_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNormal (None, 10, 10, 2048)  8192        block14_sepconv2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activation (None, 10, 10, 2048)  0           block14_sepconv2_bn[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glob (None, 2048)          0           block14_sepconv2_act[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 682)           1397418     global_average_pooling2d_6[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 682)           0           dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "predictions (Dense)              (None, 1)             683         dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 22,259,581\n",
      "Trainable params: 1,398,101\n",
      "Non-trainable params: 20,861,480\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3/4 [=====================>........] - ETA: 1s - loss: 0.7150 - acc: 0.4479 - mean_squared_logarithmic_error: 0.1439Epoch 00000: acc improved from -inf to 0.42969, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 14s - loss: 0.7205 - acc: 0.4297 - mean_squared_logarithmic_error: 0.1457 - val_loss: 0.7096 - val_acc: 0.4222 - val_mean_squared_logarithmic_error: 0.1486\n",
      "Epoch 2/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6739 - acc: 0.6010 - mean_squared_logarithmic_error: 0.1380Epoch 00001: acc improved from 0.42969 to 0.55963, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 6s - loss: 0.6793 - acc: 0.5663 - mean_squared_logarithmic_error: 0.1384 - val_loss: 0.7008 - val_acc: 0.4370 - val_mean_squared_logarithmic_error: 0.1462\n",
      "Epoch 3/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6987 - acc: 0.5633 - mean_squared_logarithmic_error: 0.1418Epoch 00002: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6917 - acc: 0.5694 - mean_squared_logarithmic_error: 0.1394 - val_loss: 0.6935 - val_acc: 0.5037 - val_mean_squared_logarithmic_error: 0.1439\n",
      "Epoch 4/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6711 - acc: 0.5905 - mean_squared_logarithmic_error: 0.1295Epoch 00003: acc improved from 0.55963 to 0.59633, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 6s - loss: 0.6701 - acc: 0.5986 - mean_squared_logarithmic_error: 0.1288 - val_loss: 0.6846 - val_acc: 0.5778 - val_mean_squared_logarithmic_error: 0.1407\n",
      "Epoch 5/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6809 - acc: 0.5729 - mean_squared_logarithmic_error: 0.1347Epoch 00004: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6919 - acc: 0.5480 - mean_squared_logarithmic_error: 0.1385 - val_loss: 0.6776 - val_acc: 0.6148 - val_mean_squared_logarithmic_error: 0.1385\n",
      "Epoch 6/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6678 - acc: 0.6146 - mean_squared_logarithmic_error: 0.1297Epoch 00005: acc improved from 0.59633 to 0.64062, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 6s - loss: 0.6638 - acc: 0.6406 - mean_squared_logarithmic_error: 0.1272 - val_loss: 0.6682 - val_acc: 0.6889 - val_mean_squared_logarithmic_error: 0.1368\n",
      "Epoch 7/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6871 - acc: 0.6058 - mean_squared_logarithmic_error: 0.1447Epoch 00006: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6760 - acc: 0.6320 - mean_squared_logarithmic_error: 0.1385 - val_loss: 0.6621 - val_acc: 0.6667 - val_mean_squared_logarithmic_error: 0.1352\n",
      "Epoch 8/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6643 - acc: 0.6314 - mean_squared_logarithmic_error: 0.1285Epoch 00007: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6830 - acc: 0.5684 - mean_squared_logarithmic_error: 0.1281 - val_loss: 0.6515 - val_acc: 0.6889 - val_mean_squared_logarithmic_error: 0.1315\n",
      "Epoch 9/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6346 - acc: 0.7452 - mean_squared_logarithmic_error: 0.1273Epoch 00008: acc improved from 0.64062 to 0.69725, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 5s - loss: 0.6484 - acc: 0.7241 - mean_squared_logarithmic_error: 0.1288 - val_loss: 0.6446 - val_acc: 0.7407 - val_mean_squared_logarithmic_error: 0.1291\n",
      "Epoch 10/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6588 - acc: 0.6562 - mean_squared_logarithmic_error: 0.1223Epoch 00009: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6453 - acc: 0.6815 - mean_squared_logarithmic_error: 0.1209 - val_loss: 0.6396 - val_acc: 0.7407 - val_mean_squared_logarithmic_error: 0.1278\n",
      "Epoch 11/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6476 - acc: 0.6667 - mean_squared_logarithmic_error: 0.1232Epoch 00010: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6458 - acc: 0.6875 - mean_squared_logarithmic_error: 0.1224 - val_loss: 0.6384 - val_acc: 0.7333 - val_mean_squared_logarithmic_error: 0.1251\n",
      "Epoch 12/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6601 - acc: 0.6482 - mean_squared_logarithmic_error: 0.1211Epoch 00011: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6665 - acc: 0.6380 - mean_squared_logarithmic_error: 0.1217 - val_loss: 0.6291 - val_acc: 0.7333 - val_mean_squared_logarithmic_error: 0.1234\n",
      "Epoch 13/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6514 - acc: 0.6266 - mean_squared_logarithmic_error: 0.1226Epoch 00012: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6540 - acc: 0.6158 - mean_squared_logarithmic_error: 0.1214 - val_loss: 0.6257 - val_acc: 0.7407 - val_mean_squared_logarithmic_error: 0.1221\n",
      "Epoch 14/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6216 - acc: 0.6891 - mean_squared_logarithmic_error: 0.1157Epoch 00013: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6330 - acc: 0.6805 - mean_squared_logarithmic_error: 0.1172 - val_loss: 0.6242 - val_acc: 0.7259 - val_mean_squared_logarithmic_error: 0.1206\n",
      "Epoch 15/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6542 - acc: 0.6354 - mean_squared_logarithmic_error: 0.1197Epoch 00014: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6387 - acc: 0.6654 - mean_squared_logarithmic_error: 0.1191 - val_loss: 0.6185 - val_acc: 0.7333 - val_mean_squared_logarithmic_error: 0.1194\n"
     ]
    }
   ],
   "source": [
    "train_top = CNN.fit_generator(train_iter, validation_data=valid_iter,\n",
    "                        callbacks=callbacks_list, steps_per_epoch=train_iter.samples//train_iter.batch_size,\n",
    "                        validation_steps=5, shuffle=True, use_multiprocessing=True, workers=1, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.4296875,\n",
       "  0.5596330302570938,\n",
       "  0.5321100928367825,\n",
       "  0.5963302779635158,\n",
       "  0.5596330277963516,\n",
       "  0.640625,\n",
       "  0.6238532131965008,\n",
       "  0.5412844053102196,\n",
       "  0.69724770696885,\n",
       "  0.6697247722826967,\n",
       "  0.6875,\n",
       "  0.6513761500699804,\n",
       "  0.6055045893432898,\n",
       "  0.6788990847561338,\n",
       "  0.6513761484294857],\n",
       " 'loss': [0.7204890102148056,\n",
       "  0.6789497935443843,\n",
       "  0.6969213305263344,\n",
       "  0.6705125635917034,\n",
       "  0.6868051492839778,\n",
       "  0.6637762039899826,\n",
       "  0.676349747618404,\n",
       "  0.6882040101453799,\n",
       "  0.6558576991798681,\n",
       "  0.6515921108219602,\n",
       "  0.6457951068878174,\n",
       "  0.6626675090658556,\n",
       "  0.6601948874806045,\n",
       "  0.6369795525839569,\n",
       "  0.64597416853686],\n",
       " 'mean_squared_logarithmic_error': [0.14570202305912971,\n",
       "  0.13764842866210764,\n",
       "  0.13979178872130332,\n",
       "  0.12885999201087778,\n",
       "  0.13672690366933105,\n",
       "  0.12718896381556988,\n",
       "  0.13685478994605738,\n",
       "  0.12793506558881987,\n",
       "  0.12850581533318267,\n",
       "  0.12154931328985669,\n",
       "  0.12238223291933537,\n",
       "  0.12163223435572527,\n",
       "  0.12188647181615916,\n",
       "  0.11827921197501891,\n",
       "  0.1193584542755687],\n",
       " 'val_acc': [0.422222223105254,\n",
       "  0.43703703769931085,\n",
       "  0.5037037039244616,\n",
       "  0.5777777786608096,\n",
       "  0.6148148154770886,\n",
       "  0.6888888897719206,\n",
       "  0.6666666668874246,\n",
       "  0.6888888897719206,\n",
       "  0.7407407416237726,\n",
       "  0.7407407409614987,\n",
       "  0.7333333342163652,\n",
       "  0.733333334657881,\n",
       "  0.7407407409614987,\n",
       "  0.7259259263674418,\n",
       "  0.733333334657881],\n",
       " 'val_loss': [0.7095680726899041,\n",
       "  0.7008107008757415,\n",
       "  0.6935361923994842,\n",
       "  0.6846392075220744,\n",
       "  0.677586265846535,\n",
       "  0.6681738434014497,\n",
       "  0.6621234673040884,\n",
       "  0.6515419527336404,\n",
       "  0.6446020174909521,\n",
       "  0.6396345619802122,\n",
       "  0.6384243779712253,\n",
       "  0.6291334827740988,\n",
       "  0.6257031127258583,\n",
       "  0.6242163472705418,\n",
       "  0.6184508222120779],\n",
       " 'val_mean_squared_logarithmic_error': [0.14863476124074723,\n",
       "  0.1461757888396581,\n",
       "  0.143925240194356,\n",
       "  0.14071002823335152,\n",
       "  0.1384827897504524,\n",
       "  0.13682463588537994,\n",
       "  0.1351715510642087,\n",
       "  0.1314702742629581,\n",
       "  0.12909212642245824,\n",
       "  0.12776491051470792,\n",
       "  0.12509410370279242,\n",
       "  0.1234321626248183,\n",
       "  0.1221180005206002,\n",
       "  0.1206041744461766,\n",
       "  0.11937290733611142]}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_top.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot this history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in CNN.layers[:len(xcpt_model.layers)]:\n",
    "#     layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN.compile(loss = tf.keras.losses.binary_crossentropy, \n",
    "#                     optimizer = tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9),\n",
    "#                     metrics=[\"acc\", tf.keras.metrics.mean_squared_logarithmic_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3/4 [=====================>........] - ETA: 2s - loss: 0.5932 - acc: 0.6979 - mean_squared_logarithmic_error: 0.1024Epoch 00000: acc did not improve\n",
      "4/4 [==============================] - 13s - loss: 0.5926 - acc: 0.6953 - mean_squared_logarithmic_error: 0.1021 - val_loss: 0.5898 - val_acc: 0.7481 - val_mean_squared_logarithmic_error: 0.1084\n",
      "Epoch 2/15\n",
      "3/4 [=====================>........] - ETA: 1s - loss: 0.5983 - acc: 0.6795 - mean_squared_logarithmic_error: 0.1033Epoch 00001: acc did not improve\n",
      "4/4 [==============================] - 9s - loss: 0.5984 - acc: 0.6865 - mean_squared_logarithmic_error: 0.1036 - val_loss: 0.5947 - val_acc: 0.7407 - val_mean_squared_logarithmic_error: 0.1090\n",
      "Epoch 3/15\n",
      "3/4 [=====================>........] - ETA: 1s - loss: 0.7191 - acc: 0.5345 - mean_squared_logarithmic_error: 0.1190"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[2048,682]\n\t [[Node: training_3/SGD/add_154 = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_4/kernel/read, training_3/SGD/sub_154)]]\n\nCaused by op 'training_3/SGD/add_154', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-89-ee8bdad87495>\", line 3, in <module>\n    validation_steps=5, shuffle=True, use_multiprocessing=True, workers=1, epochs=15)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py\", line 1964, in fit_generator\n    self._make_train_function()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py\", line 952, in _make_train_function\n    params=self._collected_trainable_weights, loss=self.total_loss)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/optimizers.py\", line 194, in get_updates\n    new_p = p + v\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 754, in _run_op\n    return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 894, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 183, in add\n    \"Add\", x=x, y=y, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2048,682]\n\t [[Node: training_3/SGD/add_154 = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_4/kernel/read, training_3/SGD/sub_154)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2048,682]\n\t [[Node: training_3/SGD/add_154 = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_4/kernel/read, training_3/SGD/sub_154)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-ee8bdad87495>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train_whole = CNN.fit_generator(train_iter, validation_data=valid_iter,\n\u001b[1;32m      2\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                         validation_steps=5, shuffle=True, use_multiprocessing=True, workers=1, epochs=15)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   2074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m           outs = self.train_on_batch(\n\u001b[0;32m-> 2076\u001b[0;31m               x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1785\u001b[0m       \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2475\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2477\u001b[0;31m         **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2478\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2048,682]\n\t [[Node: training_3/SGD/add_154 = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_4/kernel/read, training_3/SGD/sub_154)]]\n\nCaused by op 'training_3/SGD/add_154', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-89-ee8bdad87495>\", line 3, in <module>\n    validation_steps=5, shuffle=True, use_multiprocessing=True, workers=1, epochs=15)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py\", line 1964, in fit_generator\n    self._make_train_function()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py\", line 952, in _make_train_function\n    params=self._collected_trainable_weights, loss=self.total_loss)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/optimizers.py\", line 194, in get_updates\n    new_p = p + v\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py\", line 754, in _run_op\n    return getattr(ops.Tensor, operator)(a._AsTensor(), *args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 894, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 183, in add\n    \"Add\", x=x, y=y, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2048,682]\n\t [[Node: training_3/SGD/add_154 = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_4/kernel/read, training_3/SGD/sub_154)]]\n"
     ]
    }
   ],
   "source": [
    "# train_whole = CNN.fit_generator(train_iter, validation_data=valid_iter,\n",
    "#                         callbacks=callbacks_list, steps_per_epoch=train_iter.samples//train_iter.batch_size,\n",
    "#                         validation_steps=5, shuffle=True, use_multiprocessing=True, workers=1, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN.compile(loss = tf.keras.losses.binary_crossentropy, \n",
    "                     optimizer = tf.keras.optimizers.SGD(lr=0.0001, momentum=0.001),\n",
    "                     metrics=[\"acc\", tf.keras.metrics.mean_squared_logarithmic_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6350 - acc: 0.6354 - mean_squared_logarithmic_error: 0.1111Epoch 00000: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6204 - acc: 0.6719 - mean_squared_logarithmic_error: 0.1106 - val_loss: 0.6257 - val_acc: 0.7481 - val_mean_squared_logarithmic_error: 0.1190\n",
      "Epoch 2/35\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6482 - acc: 0.6731 - mean_squared_logarithmic_error: 0.1187Epoch 00001: acc did not improve\n",
      "4/4 [==============================] - 4s - loss: 0.6541 - acc: 0.6735 - mean_squared_logarithmic_error: 0.1198 - val_loss: 0.6248 - val_acc: 0.7481 - val_mean_squared_logarithmic_error: 0.1189\n",
      "Epoch 3/35\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6185 - acc: 0.7147 - mean_squared_logarithmic_error: 0.1135Epoch 00002: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6277 - acc: 0.6896 - mean_squared_logarithmic_error: 0.1144 - val_loss: 0.6214 - val_acc: 0.7556 - val_mean_squared_logarithmic_error: 0.1186\n",
      "Epoch 4/35\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6291 - acc: 0.6939 - mean_squared_logarithmic_error: 0.1185Epoch 00003: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6227 - acc: 0.7139 - mean_squared_logarithmic_error: 0.1180 - val_loss: 0.6235 - val_acc: 0.7481 - val_mean_squared_logarithmic_error: 0.1186\n",
      "Epoch 5/35\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6582 - acc: 0.6354 - mean_squared_logarithmic_error: 0.1168Epoch 00004: acc did not improve\n",
      "4/4 [==============================] - 4s - loss: 0.6510 - acc: 0.6482 - mean_squared_logarithmic_error: 0.1162 - val_loss: 0.6273 - val_acc: 0.7407 - val_mean_squared_logarithmic_error: 0.1188\n",
      "Epoch 6/35\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6472 - acc: 0.6562 - mean_squared_logarithmic_error: 0.1166Epoch 00005: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6413 - acc: 0.6719 - mean_squared_logarithmic_error: 0.1164 - val_loss: 0.6271 - val_acc: 0.7481 - val_mean_squared_logarithmic_error: 0.1194\n",
      "Epoch 7/35\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6477 - acc: 0.6579 - mean_squared_logarithmic_error: 0.1172Epoch 00006: acc did not improve\n",
      "4/4 [==============================] - 4s - loss: 0.6590 - acc: 0.6320 - mean_squared_logarithmic_error: 0.1181 - val_loss: 0.6225 - val_acc: 0.7556 - val_mean_squared_logarithmic_error: 0.1190\n",
      "Epoch 8/35\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6028 - acc: 0.7364 - mean_squared_logarithmic_error: 0.1133Epoch 00007: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6247 - acc: 0.7118 - mean_squared_logarithmic_error: 0.1157 - val_loss: 0.6210 - val_acc: 0.7556 - val_mean_squared_logarithmic_error: 0.1187\n",
      "Epoch 9/35\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6668 - acc: 0.6474 - mean_squared_logarithmic_error: 0.1206Epoch 00008: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6489 - acc: 0.6805 - mean_squared_logarithmic_error: 0.1187 - val_loss: 0.6270 - val_acc: 0.7407 - val_mean_squared_logarithmic_error: 0.1188\n",
      "Epoch 10/35\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6424 - acc: 0.6562 - mean_squared_logarithmic_error: 0.1145Epoch 00009: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6387 - acc: 0.6643 - mean_squared_logarithmic_error: 0.1130 - val_loss: 0.6179 - val_acc: 0.7630 - val_mean_squared_logarithmic_error: 0.1185\n",
      "Epoch 11/35\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6495 - acc: 0.6771 - mean_squared_logarithmic_error: 0.1178Epoch 00010: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6460 - acc: 0.6719 - mean_squared_logarithmic_error: 0.1173 - val_loss: 0.6205 - val_acc: 0.7556 - val_mean_squared_logarithmic_error: 0.1186\n",
      "Epoch 12/35\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6369 - acc: 0.6787 - mean_squared_logarithmic_error: 0.1167Epoch 00011: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6524 - acc: 0.6643 - mean_squared_logarithmic_error: 0.1187 - val_loss: 0.6235 - val_acc: 0.7481 - val_mean_squared_logarithmic_error: 0.1187\n",
      "Epoch 13/35\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6363 - acc: 0.6995 - mean_squared_logarithmic_error: 0.1181Epoch 00012: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6251 - acc: 0.7047 - mean_squared_logarithmic_error: 0.1175 - val_loss: 0.6226 - val_acc: 0.7481 - val_mean_squared_logarithmic_error: 0.1185\n",
      "Epoch 14/35\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6855 - acc: 0.5809 - mean_squared_logarithmic_error: 0.1166Epoch 00013: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6746 - acc: 0.6046 - mean_squared_logarithmic_error: 0.1173 - val_loss: 0.6272 - val_acc: 0.7407 - val_mean_squared_logarithmic_error: 0.1190\n",
      "Epoch 15/35\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6449 - acc: 0.6875 - mean_squared_logarithmic_error: 0.1181Epoch 00014: acc did not improve\n",
      "4/4 [==============================] - 4s - loss: 0.6435 - acc: 0.6714 - mean_squared_logarithmic_error: 0.1164 - val_loss: 0.6276 - val_acc: 0.7407 - val_mean_squared_logarithmic_error: 0.1191\n",
      "Epoch 16/35\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6527 - acc: 0.6771 - mean_squared_logarithmic_error: 0.1176Epoch 00015: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6496 - acc: 0.6797 - mean_squared_logarithmic_error: 0.1172 - val_loss: 0.6205 - val_acc: 0.7556 - val_mean_squared_logarithmic_error: 0.1185\n",
      "Epoch 17/35\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6096 - acc: 0.7252 - mean_squared_logarithmic_error: 0.1130Epoch 00016: acc did not improve\n",
      "4/4 [==============================] - 4s - loss: 0.6174 - acc: 0.7058 - mean_squared_logarithmic_error: 0.1124 - val_loss: 0.6295 - val_acc: 0.7407 - val_mean_squared_logarithmic_error: 0.1196\n",
      "Epoch 18/35\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6408 - acc: 0.6787 - mean_squared_logarithmic_error: 0.1170Epoch 00017: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6406 - acc: 0.6562 - mean_squared_logarithmic_error: 0.1150 - val_loss: 0.6223 - val_acc: 0.7481 - val_mean_squared_logarithmic_error: 0.1184\n",
      "Epoch 19/35\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6242 - acc: 0.6739 - mean_squared_logarithmic_error: 0.1124Epoch 00018: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6274 - acc: 0.6714 - mean_squared_logarithmic_error: 0.1128 - val_loss: 0.6235 - val_acc: 0.7481 - val_mean_squared_logarithmic_error: 0.1187\n",
      "Epoch 00018: early stopping\n"
     ]
    }
   ],
   "source": [
    "train_top = CNN.fit_generator(train_iter, validation_data=valid_iter,\n",
    "                        callbacks=callbacks_list, steps_per_epoch=train_iter.samples//train_iter.batch_size,\n",
    "                        validation_steps=5, shuffle=True, use_multiprocessing=True, workers=1, epochs=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.671875,\n",
       "  0.6605504603560911,\n",
       "  0.6788990842093021,\n",
       "  0.7064220199891187,\n",
       "  0.6422018370497118,\n",
       "  0.671875,\n",
       "  0.6238532131965008,\n",
       "  0.7247706449359929,\n",
       "  0.6788990847561338,\n",
       "  0.6605504609029228,\n",
       "  0.671875,\n",
       "  0.6605504609029228,\n",
       "  0.7064220205359503,\n",
       "  0.6238532112825901,\n",
       "  0.6788990853029654,\n",
       "  0.6796875,\n",
       "  0.6972477080625131,\n",
       "  0.6513761489763172,\n",
       "  0.6788990853029654],\n",
       " 'loss': [0.6203770339488983,\n",
       "  0.6587747865860615,\n",
       "  0.6323120298735593,\n",
       "  0.6285921608636139,\n",
       "  0.654374239641592,\n",
       "  0.6412542313337326,\n",
       "  0.6627851161388082,\n",
       "  0.6190384429529172,\n",
       "  0.6457291327485251,\n",
       "  0.6404118023881125,\n",
       "  0.6460093855857849,\n",
       "  0.6598478424439737,\n",
       "  0.6261369864875024,\n",
       "  0.662811155166101,\n",
       "  0.6441728702378929,\n",
       "  0.649566188454628,\n",
       "  0.6202566076856141,\n",
       "  0.6397823926505692,\n",
       "  0.6252664486202625],\n",
       " 'mean_squared_logarithmic_error': [0.11058389768004417,\n",
       "  0.11993018209660819,\n",
       "  0.11453115386426996,\n",
       "  0.11848423794048642,\n",
       "  0.11648108523099794,\n",
       "  0.11644170619547367,\n",
       "  0.11844588194144975,\n",
       "  0.11557081827056517,\n",
       "  0.11774578881919931,\n",
       "  0.11369337483283577,\n",
       "  0.1172814778983593,\n",
       "  0.12007168454861422,\n",
       "  0.11801933907314179,\n",
       "  0.11683133565778032,\n",
       "  0.11717028478416827,\n",
       "  0.11719262227416039,\n",
       "  0.11208671208368529,\n",
       "  0.11484287419450392,\n",
       "  0.11302936371039907],\n",
       " 'val_acc': [0.748148148589664,\n",
       "  0.7481481494726958,\n",
       "  0.7555555559970715,\n",
       "  0.748148148589664,\n",
       "  0.7407407411822566,\n",
       "  0.7481481490311799,\n",
       "  0.7555555564385873,\n",
       "  0.7555555564385873,\n",
       "  0.7407407416237726,\n",
       "  0.7629629642875106,\n",
       "  0.7555555559970715,\n",
       "  0.748148148589664,\n",
       "  0.7481481490311799,\n",
       "  0.7407407416237726,\n",
       "  0.7407407411822566,\n",
       "  0.7555555564385873,\n",
       "  0.7407407420652884,\n",
       "  0.7481481481481481,\n",
       "  0.7481481494726958],\n",
       " 'val_loss': [0.6257112357351515,\n",
       "  0.6248492360115051,\n",
       "  0.6213538642282839,\n",
       "  0.6235225787869206,\n",
       "  0.627300148098557,\n",
       "  0.627138004038069,\n",
       "  0.6224631971783108,\n",
       "  0.6210098686041655,\n",
       "  0.6270441761723271,\n",
       "  0.6179121648823773,\n",
       "  0.6205187457579153,\n",
       "  0.6235172377692328,\n",
       "  0.622637360184281,\n",
       "  0.6271950191921658,\n",
       "  0.6276065826416015,\n",
       "  0.6204975335686295,\n",
       "  0.6294508413032249,\n",
       "  0.6222979037849992,\n",
       "  0.6235122742476287],\n",
       " 'val_mean_squared_logarithmic_error': [0.11901558598986378,\n",
       "  0.11890979387142041,\n",
       "  0.11862212121486664,\n",
       "  0.11857837565519191,\n",
       "  0.11882297098636627,\n",
       "  0.119417769268707,\n",
       "  0.11896705804047761,\n",
       "  0.11865385958441982,\n",
       "  0.1187942146703049,\n",
       "  0.11850834687550862,\n",
       "  0.11863082432084614,\n",
       "  0.11872100686585461,\n",
       "  0.11845343300589808,\n",
       "  0.11900626200216788,\n",
       "  0.11914193293562642,\n",
       "  0.1185051828622818,\n",
       "  0.11956309957636727,\n",
       "  0.11843760444058313,\n",
       "  0.11872512863741981]}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_top.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5690585320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(19),train_top.history['mean_squared_logarithmic_error']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAEgVJREFUeJzt3X+M5PVdx/HXq3dUjhs8Wo9OyR26/NGQ4G1VboJUFGdLS06OcCaSeIQi19BstLZFPUMOjRJNGkkMtdWakAsgKJRF+aH0aCsXuJWYALoLtHtwtCX10nKFOyhydOEirn37x87q7DKz853v9zs/9rPPR7Jh5vvzdZ+5efHd7+58zhEhAEA63jXoAACAclHsAJAYih0AEkOxA0BiKHYASAzFDgCJodgBIDEUOwAkhmIHgMSs7efJNm7cGCMjI4uWvfnmm1q/fn0/Y3SNjOUgYznIWI6VlHF6evrViDg9844R0bevrVu3xlIHDhx4x7JhQ8ZykLEcZCzHSsooaSq66FpuxQBAYih2AEgMxQ4AiaHYASAxFDsAJKZjsdu+zfYx2wdbrNttO2xv7E08AEC3slyx3y5p29KFts+UdLGk75acCQBQQMdij4jHJL3WYtVfSLpOEv+2HgAMkVz32G3vkHQkIr5ech4AQEGODP+Yte0RSfsiYovtUyQdkHRxRBy3fVhSLSJebbPvuKRxSapWq1snJiYWrZ+dnVWlUinyZ+i51ZZx5sjxZdePbtqQ67irbRx7hYzlWEkZx8bGpiOilnW/PMU+KukRSW81Vm+W9H1J50XEy8sdp1arxdTU1KJlk5OTqtfrWfMOxGrLOLLnoWXXH75xe67jrrZx7BUylmMlZbTdVbF3PQlYRMxIet/C805X7ACA/sry6453S3pc0tm2X7R9Te9jAQDy6njFHhFXdFg/UloaAEBhfPIUABJDsQNAYih2AEgMxQ4AiaHYASAxFDsAJIZiB4DEUOwAkBiKHQASQ7EDQGIodgBIDMUOAImh2AEgMRQ7ACSGYgeAxFDsAJAYih0AEkOxA0BiKHYASAzFDgCJodgBIDEdi932bbaP2T7YtOzPbT9v+xu2H7B9Wm9jAgCyynLFfrukbUuW7Ze0JSI+KOlbkq4vORcAIKeOxR4Rj0l6bcmyhyNirvH0CUmbe5ANAJCDI6LzRvaIpH0RsaXFui9Luici7myz77ikcUmqVqtbJyYmFq2fnZ1VpVLpOng/rbaMM0eOL7t+dNOGXMddbePYK2Qsx0rKODY2Nh0Rtaz7rS1yUtt/KGlO0l3ttomIvZL2SlKtVot6vb5o/eTkpJYuGzarLeOuPQ8tu/7wlfnOs9rGsVfIWI6UM+Yudtu7JF0q6aLIctkPAOiLXMVue5uk6yT9ckS8VW4kAEARWX7d8W5Jj0s62/aLtq+R9EVJp0rab/sZ2zf3OCcAIKOOV+wRcUWLxbf2IAsAoAR88hQAEkOxA0BiKHYASAzFDgCJodgBIDEUOwAkhmIHgMRQ7ACQGIodABJTaHZHFDPSaRbFG7cP7NxF9u1l7l5Z+DPtHp1rObvlSvwzYfXiih0AEkOxA0BiKHYASAzFDgCJodgBIDEUOwAkhmIHgMRQ7ACQGIodABJDsQNAYjoWu+3bbB+zfbBp2Xtt77f97cZ/39PbmACArLJcsd8uaduSZXskPRIRH5D0SOM5AGAIdCz2iHhM0mtLFu+QdEfj8R2SfrXkXACAnPLeY69GxEuNxy9LqpaUBwBQkCOi80b2iKR9EbGl8fz1iDitaf1/RkTL++y2xyWNS1K1Wt06MTGxaP3s7KwqlUre/KWYOXJ82fVnbVjTk4ydzju6aUPmY3U7jp3OXUS73MPwWrezMB7VddLRE+9c381r0WvDPI4LyFiOhYxjY2PTEVHLul/e+diP2j4jIl6yfYakY+02jIi9kvZKUq1Wi3q9vmj95OSkli7rt1bzbze7fdv6nmTsdN7DV2Y/Z7fj2OncRbTLPQyvdTu7muZjv2nmnW+Lbl6LXhvmcVxAxnLkzZj3VsyDkq5uPL5a0j/lPA4AoGRZft3xbkmPSzrb9ou2r5F0o6SP2v62pI80ngMAhkDHWzERcUWbVReVnAUAUAI+eQoAiaHYASAxFDsAJIZiB4DEUOwAkBiKHQASQ7EDQGIodgBIDMUOAImh2AEgMRQ7ACSGYgeAxFDsAJAYih0AEkOxA0BiKHYASAzFDgCJodgBIDEUOwAkhmIHgMRQ7ACQmELFbvt3bT9r+6Dtu22fXFYwAEA+uYvd9iZJn5FUi4gtktZI2llWMABAPkVvxayVtM72WkmnSPp+8UgAgCIcEfl3tq+V9FlJJyQ9HBFXtthmXNK4JFWr1a0TExOL1s/OzqpSqeTOUIaZI8eXXV9dJx090Xrd6KYNPTtvN8fudhw7nbsXquuk9703/3j10sJ4tHuti7zOZRuG90wnZCzHQsaxsbHpiKhl3S93sdt+j6T7JP26pNcl/YOkeyPiznb71Gq1mJqaWrRscnJS9Xo9V4ayjOx5aNn1u0fndNPM2pbrDt+4vWfn7ebY3Y5jp3P3wu7ROX36yh19P28WC+PR7rUu8jqXbRjeM52QsRwLGW13VexFbsV8RNJ/RMQrEfHfku6X9AsFjgcAKEGRYv+upPNtn2Lbki6SdKicWACAvHIXe0Q8KeleSU9Jmmkca29JuQAAObW+cZxRRNwg6YaSsgAASsAnTwEgMRQ7ACSGYgeAxFDsAJAYih0AEkOxA0BiKHYASAzFDgCJodgBIDGFPnm6UvRyJsMyZ2js9tjNdo/OadcAZmzsVtHXYlCzLBbJPUwzQ64EvXxPrRZcsQNAYih2AEgMxQ4AiaHYASAxFDsAJIZiB4DEUOwAkBiKHQASQ7EDQGIodgBITKFit32a7XttP2/7kO0PlRUMAJBP0bliviDpaxFxue13SzqlhEwAgAJyF7vtDZIulLRLkiLibUlvlxMLAJBXkVsxZ0l6RdLf2H7a9i2215eUCwCQkyMi3452TdITki6IiCdtf0HSGxHxR0u2G5c0LknVanXrxMTEouPMzs6qUqnkypDVzJHjhfavrpOOnsi37+imDW3XFc3VrEjGfikj43LjWcTCa9GLcSw7cz/eM0UVydjpfVHWeK6kcRwbG5uOiFrW/YoU+/slPRERI43nvyRpT0S0nSy5VqvF1NTUomWTk5Oq1+u5MmRVdA7w3aNzumkm312r5eaOLnOe+CIZ+6WMjL2ai3vhtejFOJaduR/vmaKKZOzXfOwraRxtd1XsuW/FRMTLkr5n++zGooskPZf3eACAchS9NPm0pLsavxHzHUkfLx4JAFBEoWKPiGckZf72AADQe3zyFAASQ7EDQGIodgBIDMUOAImh2AEgMRQ7ACSGYgeAxFDsAJAYih0AEkOxA0Bihns6QKAL/ZoVsFvDmmuQypzZFO/EFTsAJIZiB4DEUOwAkBiKHQASQ7EDQGIodgBIDMUOAImh2AEgMRQ7ACSGYgeAxBQudttrbD9te18ZgQAAxZRxxX6tpEMlHAcAUIJCxW57s6Ttkm4pJw4AoKiiV+yfl3SdpB+VkAUAUAJHRL4d7UslXRIRn7Rdl/T7EXFpi+3GJY1LUrVa3ToxMbFo/ezsrCqVSq4MWc0cOV5o/+o66eiJksL0yGrJOLppQ9t1RV9naTDjuNyfqZV+vGeK6pSxyGvV7Xi1s5LGcWxsbDoialn3K1LsfybpKklzkk6W9OOS7o+Ij7Xbp1arxdTU1KJlk5OTqtfruTJkVXTu592jc7ppZrinrl8tGZebu7yMOb4HMY7dzsfej/dMUZ0yFnmtypq/fiWNo+2uij33rZiIuD4iNkfEiKSdkh5drtQBAP3B77EDQGJK+Z4zIiYlTZZxLABAMVyxA0BiKHYASAzFDgCJodgBIDEUOwAkhmIHgMRQ7ACQGIodABJDsQNAYoZ71qgmnSYNKmtiIGCYtPp7v3t0TrtKmPCs03umyERdZWVEPlyxA0BiKHYASAzFDgCJodgBIDEUOwAkhmIHgMRQ7ACQGIodABJDsQNAYih2AEgMxQ4Aicld7LbPtH3A9nO2n7V9bZnBAAD5FJkEbE7S7oh4yvapkqZt74+I50rKBgDIIfcVe0S8FBFPNR7/UNIhSZvKCgYAyMcRUfwg9oikxyRtiYg3lqwblzQuSdVqdevExMSifWdnZ1WpVDqeY+bI8cI586quk46eGNjpMyFjOQaRcXTThrbrWv29Zxzzax7rrN0zSAsZx8bGpiOilnW/wsVuuyLpXyR9NiLuX27bWq0WU1NTi5ZNTk6qXq93PE+RuaGL2j06p5tmhnvqejKWYxAZl5sXvd187IxjPs1jnbV7Bmkho+2uir3Qb8XYPknSfZLu6lTqAID+KPJbMZZ0q6RDEfG58iIBAIoocsV+gaSrJH3Y9jONr0tKygUAyCn3TbCI+FdJLjELAKAEfPIUABJDsQNAYih2AEgMxQ4AiaHYASAxFDsAJIZiB4DEUOwAkBiKHQASM3zTrwGrzCBnLl1tmsd69+icdnUx9svNwrn02Hn2LxNX7ACQGIodABJDsQNAYih2AEgMxQ4AiaHYASAxFDsAJIZiB4DEUOwAkBiKHQASU6jYbW+z/U3bL9jeU1YoAEB+uYvd9hpJfy3pVySdI+kK2+eUFQwAkE+RK/bzJL0QEd+JiLclTUjaUU4sAEBeRYp9k6TvNT1/sbEMADBAjoh8O9qXS9oWEZ9oPL9K0s9HxKeWbDcuabzx9GxJ31xyqI2SXs0Von/IWA4yloOM5VhJGX8qIk7PulOR+diPSDqz6fnmxrJFImKvpL3tDmJ7KiJqBXL0HBnLQcZykLEcKWcscivm3yV9wPZZtt8taaekBwscDwBQgtxX7BExZ/tTkv5Z0hpJt0XEs6UlAwDkUuifxouIr0j6SsEMbW/TDBEyloOM5SBjOZLNmPuHpwCA4cSUAgCQmL4Uu+3bbB+zfbDNetv+y8bUBN+wfW4/cnWZsW77uO1nGl9/3Od8Z9o+YPs528/avrbFNgMdx4wZBz2OJ9v+N9tfb2T8kxbb/Jjtexrj+KTtkSHMuMv2K03j+Il+ZmzKscb207b3tVg30HFsyrFcxmEZx8O2ZxoZplqs7+69HRE9/5J0oaRzJR1ss/4SSV+VZEnnS3qyH7m6zFiXtK/fuZrOf4akcxuPT5X0LUnnDNM4Zsw46HG0pErj8UmSnpR0/pJtPinp5sbjnZLuGcKMuyR9cVDj2JTj9yR9qdVrOuhxzJhxWMbxsKSNy6zv6r3dlyv2iHhM0mvLbLJD0t/GvCcknWb7jH5kW5Ah40BFxEsR8VTj8Q8lHdI7P+k70HHMmHGgGmMz23h6UuNr6Q+adki6o/H4XkkX2XafImbNOHC2N0vaLumWNpsMdBylTBlXiq7e28Nyj32lTE/woca3x1+1/dODCtH4lvbnNH8l12xoxnGZjNKAx7Hxrfkzko5J2h8RbccxIuYkHZf0E0OWUZJ+rfFt+b22z2yxvtc+L+k6ST9qs37g46jOGaXBj6M0/z/uh21Pe/7T+kt19d4elmJfCZ7S/Md6f0bSX0n6x0GEsF2RdJ+k34mINwaRoZMOGQc+jhHxPxHxs5r/tPR5trf0O0MnGTJ+WdJIRHxQ0n79/5VxX9i+VNKxiJju53m7kTHjQMexyS9GxLmany33t21fWORgw1LsmaYnGKSIeGPh2+OY//39k2xv7GcG2ydpvjDvioj7W2wy8HHslHEYxrEpy+uSDkjatmTV/42j7bWSNkj6QX/TzWuXMSJ+EBH/1Xh6i6StfY52gaTLbB/W/MyuH7Z955JtBj2OHTMOwTgu5DjS+O8xSQ9ofvbcZl29t4el2B+U9BuNn/yeL+l4RLw06FDNbL9/4f6g7fM0P3Z9+0vaOPetkg5FxOfabDbQccyScQjG8XTbpzUer5P0UUnPL9nsQUlXNx5fLunRaPwEa1gyLrm/epnmf57RNxFxfURsjogRzf9g9NGI+NiSzQY6jlkyDnocGxnW2z514bGkiyUt/e28rt7bhT55mpXtuzX/2xAbbb8o6QbN/0BIEXGz5j+9eomkFyS9Jenj/cjVZcbLJf2W7TlJJyTt7OdfUs1ffVwlaaZx71WS/kDSTzZlHPQ4Zsk46HE8Q9Idnv+HYt4l6e8jYp/tP5U0FREPav5/Tn9n+wXN/0B9Zx/zZc34GduXSZprZNzV54wtDdk4tjSE41iV9EDjemetpC9FxNds/6aU773NJ08BIDHDcisGAFASih0AEkOxA0BiKHYASAzFDgCJodgBIDEUOwAkhmIHgMT8L/n95jz5htTFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f569279b358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_inc.SAD.hist(bins=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    212.000000\n",
       "mean       2.589151\n",
       "std        0.883783\n",
       "min        1.130000\n",
       "25%        1.900000\n",
       "50%        2.405000\n",
       "75%        3.160000\n",
       "max        4.840000\n",
       "Name: SAD, dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inc.SAD.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./SAD'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newpath = r'./{}'.format('SAD') \n",
    "newpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Program Files\\\\arbitrary'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newpath = r'C:\\Program Files\\arbitrary' \n",
    "newpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_direct(cl):\n",
    "    newpath = r'./{}'.format(cl)\n",
    "    if not os.path.exists(newpath):\n",
    "        os.makedirs(newpath)\n",
    "        os.makedirs(newpath+'/train')\n",
    "        os.makedirs(newpath+'/train/pos')\n",
    "        os.makedirs(newpath+'/train/neg')\n",
    "        os.makedirs(newpath+'/valid')\n",
    "        os.makedirs(newpath+'/valid/pos')\n",
    "        os.makedirs(newpath+'/valid/neg')\n",
    "\n",
    "def cl_setup_folds(cl):\n",
    "    os.mkdir('/'+str(cl)+'/train')\n",
    "    os.mkdir('/'+str(cl)+'/train/pos')\n",
    "    os.mkdir('/'+str(cl)+'/train/neg')\n",
    "    os.mkdir('/'+str(cl)+'/valid')\n",
    "    os.mkdir('/'+str(cl)+'/valid/pos')\n",
    "    os.mkdir('/'+str(cl)+'/valid/neg')\n",
    "    \n",
    "folds = []\n",
    "for fold_idx, split in enumerate(folder.split(X=df_inc.index.values)):\n",
    "    folds.append(split)\n",
    "\n",
    "def cl_run_k_fold(k, cl, threshold):\n",
    "    fold = folds[k]\n",
    "    path = r'./{}'.format(cl)\n",
    "    train_df = df_inc.loc[fold[0]]\n",
    "    train_pos = train_df.loc[train_df['{}'.format(cl)].map(lambda x : True if x > threshold else False)]\n",
    "    train_neg = train_df.loc[train_df['{}'.format(cl)].map(lambda x : True if x <= threshold else False)]\n",
    "    valid_df = df_inc.loc[fold[1]]\n",
    "    valid_pos = valid_df.loc[valid_df['{}'.format(cl)].map(lambda x : True if x > threshold else False)]\n",
    "    valid_neg = valid_df.loc[valid_df['{}'.format(cl)].map(lambda x : True if x <= threshold else False)]\n",
    "    for member in train_pos['jpeg_names'].values:\n",
    "        os.link(member, os.path.join(os.path.abspath(path+'/train/pos'), member))\n",
    "    for member in train_neg['jpeg_names'].values:\n",
    "        os.link(member, os.path.join(os.path.abspath(path+'/train/neg'), member))\n",
    "    for member in valid_pos['jpeg_names'].values:\n",
    "        os.link(member, os.path.join(os.path.abspath(path+'/valid/pos'), member))\n",
    "    for member in valid_neg['jpeg_names'].values:\n",
    "        os.link(member, os.path.join(os.path.abspath(path+'/valid/neg'), member))\n",
    "        \n",
    "def cl_clean_up_folds(cl):\n",
    "    path = r'./{}'.format(cl)\n",
    "    def clean_up(folder):\n",
    "        for the_file in os.listdir(folder):\n",
    "            file_path = os.path.join(folder, the_file)\n",
    "            try:\n",
    "                if os.path.isfile(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    clean_up(newpath+'/train')\n",
    "    os.rmdir(newpath+'/train')\n",
    "    clean_up(newpath+'/valid')\n",
    "    os.rmdir(newpath+'/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_direct('SAD')\n",
    "create_direct('SUR')\n",
    "create_direct('ANG')\n",
    "create_direct('DIS')\n",
    "create_direct('FEA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = []\n",
    "for fold_idx, split in enumerate(folder.split(X=df_inc.index.values)):\n",
    "    folds.append(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:27: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:30: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    }
   ],
   "source": [
    "cl_run_k_fold(0, 'SAD', 2.589151)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 135 images belonging to 2 classes.\n",
      "Found 70 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_feed = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=20, width_shift_range=0.2,\n",
    "    height_shift_range=0.2, preprocessing_function=tf.keras.applications.xception.preprocess_input)\n",
    "train_iter = train_feed.flow_from_directory(\n",
    "    './SAD/train/', target_size=(299, 299), follow_links=True, class_mode='binary')\n",
    "valid_feed = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=0, width_shift_range=0,\n",
    "    height_shift_range=0, preprocessing_function=tf.keras.applications.xception.preprocess_input)\n",
    "valid_iter = valid_feed.flow_from_directory(\n",
    "    './SAD/valid/', target_size=(299, 299), follow_links=True, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcpt_model = tf.keras.applications.Xception(include_top=False, weights='imagenet', input_shape=(299, 299, 3), \n",
    "                                              classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xcpt_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(682, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(rate=0.3)(x)\n",
    "predictions = tf.keras.layers.Dense(1, 'sigmoid', bias_initializer='Zeros', \n",
    "                          kernel_initializer=tf.keras.initializers.glorot_uniform(),\n",
    "                          trainable=True, use_bias=True, name='predictions')(x)\n",
    "CNN = tf.keras.models.Model(inputs=xcpt_model.inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in CNN.layers[:len(xcpt_model.layers)]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN.compile(loss = tf.keras.losses.binary_crossentropy, \n",
    "                    optimizer = tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9),\n",
    "                    metrics=[\"acc\", tf.keras.metrics.mean_squared_logarithmic_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_weights_path = '/home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5'\n",
    "callbacks_list = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(top_weights_path, monitor='acc',\n",
    "                                       verbose=1, save_best_only=True),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='acc', patience=10, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3/4 [=====================>........] - ETA: 2s - loss: 0.6984 - acc: 0.5521 - mean_squared_logarithmic_error: 0.1316Epoch 00000: acc improved from -inf to 0.53906, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 20s - loss: 0.6973 - acc: 0.5391 - mean_squared_logarithmic_error: 0.1318 - val_loss: 0.6942 - val_acc: 0.5896 - val_mean_squared_logarithmic_error: 0.1261\n",
      "Epoch 2/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6976 - acc: 0.4554 - mean_squared_logarithmic_error: 0.1369Epoch 00001: acc did not improve\n",
      "4/4 [==============================] - 7s - loss: 0.6997 - acc: 0.4602 - mean_squared_logarithmic_error: 0.1385 - val_loss: 0.6926 - val_acc: 0.5970 - val_mean_squared_logarithmic_error: 0.1260\n",
      "Epoch 3/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7287 - acc: 0.4137 - mean_squared_logarithmic_error: 0.1338Epoch 00002: acc did not improve\n",
      "4/4 [==============================] - 7s - loss: 0.7246 - acc: 0.4274 - mean_squared_logarithmic_error: 0.1333 - val_loss: 0.6919 - val_acc: 0.5896 - val_mean_squared_logarithmic_error: 0.1250\n",
      "Epoch 4/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6785 - acc: 0.5923 - mean_squared_logarithmic_error: 0.1314Epoch 00003: acc did not improve\n",
      "4/4 [==============================] - 7s - loss: 0.6879 - acc: 0.5376 - mean_squared_logarithmic_error: 0.1315 - val_loss: 0.6901 - val_acc: 0.5896 - val_mean_squared_logarithmic_error: 0.1250\n",
      "Epoch 5/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6879 - acc: 0.5208 - mean_squared_logarithmic_error: 0.1307Epoch 00004: acc did not improve\n",
      "4/4 [==============================] - 7s - loss: 0.6975 - acc: 0.5011 - mean_squared_logarithmic_error: 0.1319 - val_loss: 0.6960 - val_acc: 0.5746 - val_mean_squared_logarithmic_error: 0.1243\n",
      "Epoch 6/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6942 - acc: 0.5104 - mean_squared_logarithmic_error: 0.1323Epoch 00005: acc did not improve\n",
      "4/4 [==============================] - 7s - loss: 0.7075 - acc: 0.4688 - mean_squared_logarithmic_error: 0.1326 - val_loss: 0.6925 - val_acc: 0.5821 - val_mean_squared_logarithmic_error: 0.1238\n",
      "Epoch 7/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6861 - acc: 0.5967 - mean_squared_logarithmic_error: 0.1327Epoch 00006: acc improved from 0.53906 to 0.56311, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 7s - loss: 0.6912 - acc: 0.5644 - mean_squared_logarithmic_error: 0.1305 - val_loss: 0.6832 - val_acc: 0.5970 - val_mean_squared_logarithmic_error: 0.1225\n",
      "Epoch 8/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6809 - acc: 0.5238 - mean_squared_logarithmic_error: 0.1271Epoch 00007: acc did not improve\n",
      "4/4 [==============================] - 6s - loss: 0.6894 - acc: 0.4989 - mean_squared_logarithmic_error: 0.1314 - val_loss: 0.6870 - val_acc: 0.6045 - val_mean_squared_logarithmic_error: 0.1231\n",
      "Epoch 9/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7233 - acc: 0.3646 - mean_squared_logarithmic_error: 0.1233Epoch 00008: acc did not improve\n",
      "4/4 [==============================] - 7s - loss: 0.7079 - acc: 0.4505 - mean_squared_logarithmic_error: 0.1246 - val_loss: 0.6849 - val_acc: 0.6045 - val_mean_squared_logarithmic_error: 0.1225\n",
      "Epoch 10/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6830 - acc: 0.6042 - mean_squared_logarithmic_error: 0.1266Epoch 00009: acc improved from 0.56311 to 0.59223, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 7s - loss: 0.7003 - acc: 0.5667 - mean_squared_logarithmic_error: 0.1274 - val_loss: 0.6834 - val_acc: 0.6119 - val_mean_squared_logarithmic_error: 0.1220\n",
      "Epoch 11/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6914 - acc: 0.5312 - mean_squared_logarithmic_error: 0.1300Epoch 00010: acc did not improve\n",
      "4/4 [==============================] - 7s - loss: 0.6957 - acc: 0.5234 - mean_squared_logarithmic_error: 0.1283 - val_loss: 0.6812 - val_acc: 0.6119 - val_mean_squared_logarithmic_error: 0.1213\n",
      "Epoch 12/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6592 - acc: 0.6131 - mean_squared_logarithmic_error: 0.1258Epoch 00011: acc did not improve\n",
      "4/4 [==============================] - 7s - loss: 0.6756 - acc: 0.5703 - mean_squared_logarithmic_error: 0.1287 - val_loss: 0.6923 - val_acc: 0.5821 - val_mean_squared_logarithmic_error: 0.1214\n",
      "Epoch 13/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6616 - acc: 0.6399 - mean_squared_logarithmic_error: 0.1228Epoch 00012: acc did not improve\n",
      "4/4 [==============================] - 7s - loss: 0.6717 - acc: 0.6009 - mean_squared_logarithmic_error: 0.1240 - val_loss: 0.6828 - val_acc: 0.6045 - val_mean_squared_logarithmic_error: 0.1209\n",
      "Epoch 14/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7118 - acc: 0.5387 - mean_squared_logarithmic_error: 0.1239Epoch 00013: acc did not improve\n",
      "4/4 [==============================] - 7s - loss: 0.7031 - acc: 0.5503 - mean_squared_logarithmic_error: 0.1231 - val_loss: 0.6859 - val_acc: 0.5970 - val_mean_squared_logarithmic_error: 0.1208\n",
      "Epoch 15/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6807 - acc: 0.5521 - mean_squared_logarithmic_error: 0.1251Epoch 00014: acc did not improve\n",
      "4/4 [==============================] - 6s - loss: 0.6646 - acc: 0.6172 - mean_squared_logarithmic_error: 0.1250 - val_loss: 0.6921 - val_acc: 0.5821 - val_mean_squared_logarithmic_error: 0.1210\n"
     ]
    }
   ],
   "source": [
    "train_top = CNN.fit_generator(train_iter, validation_data=valid_iter,\n",
    "                        callbacks=callbacks_list, steps_per_epoch=train_iter.samples//train_iter.batch_size,\n",
    "                        validation_steps=5, shuffle=True, use_multiprocessing=True, workers=1, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    212.000000\n",
       "mean       2.465896\n",
       "std        0.969596\n",
       "min        1.030000\n",
       "25%        1.770000\n",
       "50%        2.190000\n",
       "75%        3.070000\n",
       "max        4.770000\n",
       "Name: ANG, dtype: float64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inc.ANG.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:27: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:30: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    }
   ],
   "source": [
    "cl_run_k_fold(0, 'ANG', 2.465896)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 135 images belonging to 2 classes.\n",
      "Found 70 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_feed = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=20, width_shift_range=0.2,\n",
    "    height_shift_range=0.2, preprocessing_function=tf.keras.applications.xception.preprocess_input)\n",
    "train_iter = train_feed.flow_from_directory(\n",
    "    './ANG/train/', target_size=(299, 299), follow_links=True, class_mode='binary')\n",
    "valid_feed = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=0, width_shift_range=0,\n",
    "    height_shift_range=0, preprocessing_function=tf.keras.applications.xception.preprocess_input)\n",
    "valid_iter = valid_feed.flow_from_directory(\n",
    "    './ANG/valid/', target_size=(299, 299), follow_links=True, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcpt_model = tf.keras.applications.Xception(include_top=False, weights='imagenet', input_shape=(299, 299, 3), \n",
    "                                              classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xcpt_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(682, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(rate=0.3)(x)\n",
    "predictions = tf.keras.layers.Dense(1, 'sigmoid', bias_initializer='Zeros', \n",
    "                          kernel_initializer=tf.keras.initializers.glorot_uniform(),\n",
    "                          trainable=True, use_bias=True, name='predictions')(x)\n",
    "CNN = tf.keras.models.Model(inputs=xcpt_model.inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in CNN.layers[:len(xcpt_model.layers)]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN.compile(loss = tf.keras.losses.binary_crossentropy, \n",
    "                    optimizer = tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9),\n",
    "                    metrics=[\"acc\", tf.keras.metrics.mean_squared_logarithmic_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_weights_path = '/home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5'\n",
    "callbacks_list = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(top_weights_path, monitor='acc',\n",
    "                                       verbose=1, save_best_only=True),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='acc', patience=10, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3/4 [=====================>........] - ETA: 1s - loss: 0.6650 - acc: 0.5417 - mean_squared_logarithmic_error: 0.1220Epoch 00000: acc improved from -inf to 0.57031, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 20s - loss: 0.6653 - acc: 0.5703 - mean_squared_logarithmic_error: 0.1211 - val_loss: 0.6534 - val_acc: 0.6119 - val_mean_squared_logarithmic_error: 0.1164\n",
      "Epoch 2/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6879 - acc: 0.5759 - mean_squared_logarithmic_error: 0.1271Epoch 00001: acc improved from 0.57031 to 0.58252, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 6s - loss: 0.6790 - acc: 0.5808 - mean_squared_logarithmic_error: 0.1253 - val_loss: 0.6434 - val_acc: 0.6343 - val_mean_squared_logarithmic_error: 0.1156\n",
      "Epoch 3/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6567 - acc: 0.6235 - mean_squared_logarithmic_error: 0.1209Epoch 00002: acc did not improve\n",
      "4/4 [==============================] - 6s - loss: 0.6571 - acc: 0.6031 - mean_squared_logarithmic_error: 0.1199 - val_loss: 0.6436 - val_acc: 0.6269 - val_mean_squared_logarithmic_error: 0.1146\n",
      "Epoch 4/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6670 - acc: 0.5967 - mean_squared_logarithmic_error: 0.1245Epoch 00003: acc improved from 0.58252 to 0.59223, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 7s - loss: 0.6647 - acc: 0.5890 - mean_squared_logarithmic_error: 0.1222 - val_loss: 0.6410 - val_acc: 0.6343 - val_mean_squared_logarithmic_error: 0.1142\n",
      "Epoch 5/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6445 - acc: 0.6458 - mean_squared_logarithmic_error: 0.1163Epoch 00004: acc improved from 0.59223 to 0.65049, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 7s - loss: 0.6367 - acc: 0.6605 - mean_squared_logarithmic_error: 0.1111 - val_loss: 0.6326 - val_acc: 0.6493 - val_mean_squared_logarithmic_error: 0.1131\n",
      "Epoch 6/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6564 - acc: 0.5938 - mean_squared_logarithmic_error: 0.1184Epoch 00005: acc did not improve\n",
      "4/4 [==============================] - 7s - loss: 0.6514 - acc: 0.6172 - mean_squared_logarithmic_error: 0.1179 - val_loss: 0.6418 - val_acc: 0.6269 - val_mean_squared_logarithmic_error: 0.1132\n",
      "Epoch 7/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7091 - acc: 0.5491 - mean_squared_logarithmic_error: 0.1208Epoch 00006: acc did not improve\n",
      "4/4 [==============================] - 6s - loss: 0.6939 - acc: 0.5749 - mean_squared_logarithmic_error: 0.1196 - val_loss: 0.6355 - val_acc: 0.6418 - val_mean_squared_logarithmic_error: 0.1126\n",
      "Epoch 8/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6599 - acc: 0.5491 - mean_squared_logarithmic_error: 0.1195Epoch 00007: acc did not improve\n",
      "4/4 [==============================] - 6s - loss: 0.6562 - acc: 0.5749 - mean_squared_logarithmic_error: 0.1188 - val_loss: 0.6370 - val_acc: 0.6343 - val_mean_squared_logarithmic_error: 0.1121\n",
      "Epoch 9/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6610 - acc: 0.5923 - mean_squared_logarithmic_error: 0.1185Epoch 00008: acc did not improve\n",
      "4/4 [==============================] - 6s - loss: 0.6593 - acc: 0.5949 - mean_squared_logarithmic_error: 0.1181 - val_loss: 0.6344 - val_acc: 0.6343 - val_mean_squared_logarithmic_error: 0.1113\n",
      "Epoch 10/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6303 - acc: 0.6458 - mean_squared_logarithmic_error: 0.1083Epoch 00009: acc improved from 0.65049 to 0.66019, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 6s - loss: 0.6163 - acc: 0.6910 - mean_squared_logarithmic_error: 0.1095 - val_loss: 0.6404 - val_acc: 0.6194 - val_mean_squared_logarithmic_error: 0.1113\n",
      "Epoch 11/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6350 - acc: 0.6250 - mean_squared_logarithmic_error: 0.1137Epoch 00010: acc did not improve\n",
      "4/4 [==============================] - 7s - loss: 0.6414 - acc: 0.6016 - mean_squared_logarithmic_error: 0.1138 - val_loss: 0.6361 - val_acc: 0.6343 - val_mean_squared_logarithmic_error: 0.1112\n",
      "Epoch 12/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6503 - acc: 0.5595 - mean_squared_logarithmic_error: 0.1103Epoch 00011: acc did not improve\n",
      "4/4 [==============================] - 6s - loss: 0.6499 - acc: 0.5830 - mean_squared_logarithmic_error: 0.1104 - val_loss: 0.6344 - val_acc: 0.6343 - val_mean_squared_logarithmic_error: 0.1106\n",
      "Epoch 13/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6187 - acc: 0.6815 - mean_squared_logarithmic_error: 0.1107Epoch 00012: acc did not improve\n",
      "4/4 [==============================] - 6s - loss: 0.6165 - acc: 0.6910 - mean_squared_logarithmic_error: 0.1106 - val_loss: 0.6328 - val_acc: 0.6343 - val_mean_squared_logarithmic_error: 0.1101\n",
      "Epoch 14/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6453 - acc: 0.6176 - mean_squared_logarithmic_error: 0.1109Epoch 00013: acc did not improve\n",
      "4/4 [==============================] - 6s - loss: 0.6540 - acc: 0.6136 - mean_squared_logarithmic_error: 0.1120 - val_loss: 0.6321 - val_acc: 0.6343 - val_mean_squared_logarithmic_error: 0.1098\n",
      "Epoch 15/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6291 - acc: 0.6354 - mean_squared_logarithmic_error: 0.1107Epoch 00014: acc did not improve\n",
      "4/4 [==============================] - 6s - loss: 0.6477 - acc: 0.5912 - mean_squared_logarithmic_error: 0.1170 - val_loss: 0.6360 - val_acc: 0.6269 - val_mean_squared_logarithmic_error: 0.1099\n"
     ]
    }
   ],
   "source": [
    "train_top = CNN.fit_generator(train_iter, validation_data=valid_iter,\n",
    "                        callbacks=callbacks_list, steps_per_epoch=train_iter.samples//train_iter.batch_size,\n",
    "                        validation_steps=5, shuffle=True, use_multiprocessing=True, workers=1, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    212.000000\n",
       "mean       2.450755\n",
       "std        1.175079\n",
       "min        1.100000\n",
       "25%        1.610000\n",
       "50%        1.840000\n",
       "75%        3.297500\n",
       "max        4.970000\n",
       "Name: SUR, dtype: float64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inc.SUR.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4507547169811317"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inc.SUR.describe()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:27: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:30: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    }
   ],
   "source": [
    "cl_run_k_fold(0, 'SUR', df_inc.SUR.describe()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 135 images belonging to 2 classes.\n",
      "Found 70 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "3/4 [=====================>........] - ETA: 1s - loss: 0.7101 - acc: 0.4479 - mean_squared_logarithmic_error: 0.1461Epoch 00000: acc improved from -inf to 0.44531, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 20s - loss: 0.7147 - acc: 0.4453 - mean_squared_logarithmic_error: 0.1481 - val_loss: 0.6614 - val_acc: 0.6791 - val_mean_squared_logarithmic_error: 0.1277\n",
      "Epoch 2/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7055 - acc: 0.4926 - mean_squared_logarithmic_error: 0.1384Epoch 00001: acc improved from 0.44531 to 0.48544, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 5s - loss: 0.7014 - acc: 0.4989 - mean_squared_logarithmic_error: 0.1402 - val_loss: 0.6597 - val_acc: 0.6940 - val_mean_squared_logarithmic_error: 0.1272\n",
      "Epoch 3/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7020 - acc: 0.4926 - mean_squared_logarithmic_error: 0.1358Epoch 00002: acc did not improve\n",
      "4/4 [==============================] - 4s - loss: 0.7128 - acc: 0.4661 - mean_squared_logarithmic_error: 0.1432 - val_loss: 0.6563 - val_acc: 0.7015 - val_mean_squared_logarithmic_error: 0.1267\n",
      "Epoch 4/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6911 - acc: 0.5923 - mean_squared_logarithmic_error: 0.1338Epoch 00003: acc improved from 0.48544 to 0.53398, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 5s - loss: 0.6935 - acc: 0.5622 - mean_squared_logarithmic_error: 0.1324 - val_loss: 0.6510 - val_acc: 0.7164 - val_mean_squared_logarithmic_error: 0.1263\n",
      "Epoch 5/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6884 - acc: 0.5729 - mean_squared_logarithmic_error: 0.1431Epoch 00004: acc improved from 0.53398 to 0.57282, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 5s - loss: 0.6885 - acc: 0.5726 - mean_squared_logarithmic_error: 0.1421 - val_loss: 0.6540 - val_acc: 0.7015 - val_mean_squared_logarithmic_error: 0.1255\n",
      "Epoch 6/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6905 - acc: 0.5417 - mean_squared_logarithmic_error: 0.1349Epoch 00005: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6965 - acc: 0.5156 - mean_squared_logarithmic_error: 0.1395 - val_loss: 0.6551 - val_acc: 0.6866 - val_mean_squared_logarithmic_error: 0.1240\n",
      "Epoch 7/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6768 - acc: 0.5179 - mean_squared_logarithmic_error: 0.1405Epoch 00006: acc improved from 0.57282 to 0.58252, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 5s - loss: 0.6720 - acc: 0.5585 - mean_squared_logarithmic_error: 0.1355 - val_loss: 0.6451 - val_acc: 0.7090 - val_mean_squared_logarithmic_error: 0.1229\n",
      "Epoch 8/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6861 - acc: 0.5967 - mean_squared_logarithmic_error: 0.1375Epoch 00007: acc improved from 0.58252 to 0.60194, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 5s - loss: 0.6765 - acc: 0.5972 - mean_squared_logarithmic_error: 0.1322 - val_loss: 0.6488 - val_acc: 0.6866 - val_mean_squared_logarithmic_error: 0.1215\n",
      "Epoch 9/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6566 - acc: 0.6443 - mean_squared_logarithmic_error: 0.1309Epoch 00008: acc improved from 0.60194 to 0.62136, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 5s - loss: 0.6663 - acc: 0.6359 - mean_squared_logarithmic_error: 0.1322 - val_loss: 0.6464 - val_acc: 0.6940 - val_mean_squared_logarithmic_error: 0.1211\n",
      "Epoch 10/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6652 - acc: 0.6458 - mean_squared_logarithmic_error: 0.1296Epoch 00009: acc improved from 0.62136 to 0.65049, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 5s - loss: 0.6511 - acc: 0.6605 - mean_squared_logarithmic_error: 0.1261 - val_loss: 0.6381 - val_acc: 0.7090 - val_mean_squared_logarithmic_error: 0.1199\n",
      "Epoch 11/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6440 - acc: 0.6562 - mean_squared_logarithmic_error: 0.1231Epoch 00010: acc improved from 0.65049 to 0.66406, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 5s - loss: 0.6444 - acc: 0.6641 - mean_squared_logarithmic_error: 0.1242 - val_loss: 0.6383 - val_acc: 0.7015 - val_mean_squared_logarithmic_error: 0.1188\n",
      "Epoch 12/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6185 - acc: 0.7589 - mean_squared_logarithmic_error: 0.1169Epoch 00011: acc improved from 0.66406 to 0.72816, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 5s - loss: 0.6317 - acc: 0.7260 - mean_squared_logarithmic_error: 0.1179 - val_loss: 0.6365 - val_acc: 0.7015 - val_mean_squared_logarithmic_error: 0.1180\n",
      "Epoch 13/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6512 - acc: 0.6711 - mean_squared_logarithmic_error: 0.1247Epoch 00012: acc did not improve\n",
      "4/4 [==============================] - 4s - loss: 0.6576 - acc: 0.6500 - mean_squared_logarithmic_error: 0.1250 - val_loss: 0.6408 - val_acc: 0.6866 - val_mean_squared_logarithmic_error: 0.1176\n",
      "Epoch 14/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6101 - acc: 0.7485 - mean_squared_logarithmic_error: 0.1191Epoch 00013: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6183 - acc: 0.7178 - mean_squared_logarithmic_error: 0.1180 - val_loss: 0.6399 - val_acc: 0.6866 - val_mean_squared_logarithmic_error: 0.1170\n",
      "Epoch 15/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6304 - acc: 0.7188 - mean_squared_logarithmic_error: 0.1194Epoch 00014: acc did not improve\n",
      "4/4 [==============================] - 4s - loss: 0.6477 - acc: 0.6568 - mean_squared_logarithmic_error: 0.1210 - val_loss: 0.6305 - val_acc: 0.7015 - val_mean_squared_logarithmic_error: 0.1157\n"
     ]
    }
   ],
   "source": [
    "train_feed = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=20, width_shift_range=0.2,\n",
    "    height_shift_range=0.2, preprocessing_function=tf.keras.applications.xception.preprocess_input)\n",
    "train_iter = train_feed.flow_from_directory(\n",
    "    './SUR/train/', target_size=(299, 299), follow_links=True, class_mode='binary')\n",
    "valid_feed = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=0, width_shift_range=0,\n",
    "    height_shift_range=0, preprocessing_function=tf.keras.applications.xception.preprocess_input)\n",
    "valid_iter = valid_feed.flow_from_directory(\n",
    "    './SUR/valid/', target_size=(299, 299), follow_links=True, class_mode='binary')\n",
    "\n",
    "xcpt_model = tf.keras.applications.Xception(include_top=False, weights='imagenet', input_shape=(299, 299, 3), \n",
    "                                              classes=1)\n",
    "\n",
    "x = xcpt_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(682, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(rate=0.3)(x)\n",
    "predictions = tf.keras.layers.Dense(1, 'sigmoid', bias_initializer='Zeros', \n",
    "                          kernel_initializer=tf.keras.initializers.glorot_uniform(),\n",
    "                          trainable=True, use_bias=True, name='predictions')(x)\n",
    "CNN = tf.keras.models.Model(inputs=xcpt_model.inputs, outputs=predictions)\n",
    "\n",
    "for layer in CNN.layers[:len(xcpt_model.layers)]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "CNN.compile(loss = tf.keras.losses.binary_crossentropy, \n",
    "                    optimizer = tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9),\n",
    "                    metrics=[\"acc\", tf.keras.metrics.mean_squared_logarithmic_error])\n",
    "\n",
    "top_weights_path = '/home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5'\n",
    "callbacks_list = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(top_weights_path, monitor='acc',\n",
    "                                       verbose=1, save_best_only=True),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='acc', patience=10, verbose=1)\n",
    "]\n",
    "\n",
    "train_top = CNN.fit_generator(train_iter, validation_data=valid_iter,\n",
    "                        callbacks=callbacks_list, steps_per_epoch=train_iter.samples//train_iter.batch_size,\n",
    "                        validation_steps=5, shuffle=True, use_multiprocessing=True, workers=1, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:27: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:30: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    }
   ],
   "source": [
    "cl_run_k_fold(0, 'DIS', df_inc.DIS.describe()[1])\n",
    "cl_run_k_fold(0, 'FEA', df_inc.FEA.describe()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 135 images belonging to 2 classes.\n",
      "Found 70 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "3/4 [=====================>........] - ETA: 2s - loss: 0.7003 - acc: 0.5000 - mean_squared_logarithmic_error: 0.1278Epoch 00000: acc improved from -inf to 0.47656, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 25s - loss: 0.7043 - acc: 0.4766 - mean_squared_logarithmic_error: 0.1302 - val_loss: 0.6874 - val_acc: 0.5746 - val_mean_squared_logarithmic_error: 0.1286\n",
      "Epoch 2/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7049 - acc: 0.4926 - mean_squared_logarithmic_error: 0.1246Epoch 00001: acc did not improve\n",
      "4/4 [==============================] - 6s - loss: 0.7054 - acc: 0.4907 - mean_squared_logarithmic_error: 0.1254 - val_loss: 0.6876 - val_acc: 0.5970 - val_mean_squared_logarithmic_error: 0.1271\n",
      "Epoch 3/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6828 - acc: 0.5923 - mean_squared_logarithmic_error: 0.1269Epoch 00002: acc improved from 0.47656 to 0.50485, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 7s - loss: 0.6889 - acc: 0.5376 - mean_squared_logarithmic_error: 0.1266 - val_loss: 0.6854 - val_acc: 0.5821 - val_mean_squared_logarithmic_error: 0.1257\n",
      "Epoch 4/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6740 - acc: 0.6027 - mean_squared_logarithmic_error: 0.1177Epoch 00003: acc improved from 0.50485 to 0.53398, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 6s - loss: 0.6852 - acc: 0.5622 - mean_squared_logarithmic_error: 0.1201 - val_loss: 0.6852 - val_acc: 0.5522 - val_mean_squared_logarithmic_error: 0.1265\n",
      "Epoch 5/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6876 - acc: 0.5729 - mean_squared_logarithmic_error: 0.1283Epoch 00004: acc improved from 0.53398 to 0.57282, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 6s - loss: 0.6873 - acc: 0.5726 - mean_squared_logarithmic_error: 0.1231 - val_loss: 0.6848 - val_acc: 0.5075 - val_mean_squared_logarithmic_error: 0.1248\n",
      "Epoch 6/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6878 - acc: 0.5104 - mean_squared_logarithmic_error: 0.1240Epoch 00005: acc did not improve\n",
      "4/4 [==============================] - 6s - loss: 0.6916 - acc: 0.5156 - mean_squared_logarithmic_error: 0.1257 - val_loss: 0.6836 - val_acc: 0.5149 - val_mean_squared_logarithmic_error: 0.1255\n",
      "Epoch 7/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6872 - acc: 0.4970 - mean_squared_logarithmic_error: 0.1287Epoch 00006: acc did not improve\n",
      "4/4 [==============================] - 6s - loss: 0.6897 - acc: 0.5175 - mean_squared_logarithmic_error: 0.1287 - val_loss: 0.6846 - val_acc: 0.5672 - val_mean_squared_logarithmic_error: 0.1242\n",
      "Epoch 8/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6855 - acc: 0.4970 - mean_squared_logarithmic_error: 0.1127Epoch 00007: acc did not improve\n",
      "4/4 [==============================] - 6s - loss: 0.6878 - acc: 0.5011 - mean_squared_logarithmic_error: 0.1154 - val_loss: 0.6833 - val_acc: 0.6045 - val_mean_squared_logarithmic_error: 0.1249\n",
      "Epoch 9/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6902 - acc: 0.5238 - mean_squared_logarithmic_error: 0.1286Epoch 00008: acc did not improve\n",
      "4/4 [==============================] - 6s - loss: 0.6888 - acc: 0.5153 - mean_squared_logarithmic_error: 0.1269 - val_loss: 0.6816 - val_acc: 0.6269 - val_mean_squared_logarithmic_error: 0.1242\n",
      "Epoch 10/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6781 - acc: 0.5625 - mean_squared_logarithmic_error: 0.1236Epoch 00009: acc did not improve\n",
      "4/4 [==============================] - 6s - loss: 0.7004 - acc: 0.4729 - mean_squared_logarithmic_error: 0.1266 - val_loss: 0.6800 - val_acc: 0.6194 - val_mean_squared_logarithmic_error: 0.1241\n",
      "Epoch 11/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6977 - acc: 0.5000 - mean_squared_logarithmic_error: 0.1265Epoch 00010: acc did not improve\n",
      "4/4 [==============================] - 6s - loss: 0.6995 - acc: 0.4688 - mean_squared_logarithmic_error: 0.1269 - val_loss: 0.6816 - val_acc: 0.6119 - val_mean_squared_logarithmic_error: 0.1223\n",
      "Epoch 12/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7003 - acc: 0.4970 - mean_squared_logarithmic_error: 0.1292Epoch 00011: acc did not improve\n",
      "4/4 [==============================] - 6s - loss: 0.6988 - acc: 0.5011 - mean_squared_logarithmic_error: 0.1264 - val_loss: 0.6786 - val_acc: 0.5970 - val_mean_squared_logarithmic_error: 0.1233\n",
      "Epoch 13/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6979 - acc: 0.5342 - mean_squared_logarithmic_error: 0.1310Epoch 00012: acc did not improve\n",
      "4/4 [==============================] - 6s - loss: 0.7012 - acc: 0.5234 - mean_squared_logarithmic_error: 0.1282 - val_loss: 0.6792 - val_acc: 0.5746 - val_mean_squared_logarithmic_error: 0.1226\n",
      "Epoch 14/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6822 - acc: 0.4926 - mean_squared_logarithmic_error: 0.1287Epoch 00013: acc did not improve\n",
      "4/4 [==============================] - 6s - loss: 0.6948 - acc: 0.4825 - mean_squared_logarithmic_error: 0.1313 - val_loss: 0.6776 - val_acc: 0.5522 - val_mean_squared_logarithmic_error: 0.1218\n",
      "Epoch 15/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6892 - acc: 0.5833 - mean_squared_logarithmic_error: 0.1207Epoch 00014: acc did not improve\n",
      "4/4 [==============================] - 6s - loss: 0.7050 - acc: 0.5198 - mean_squared_logarithmic_error: 0.1280 - val_loss: 0.6763 - val_acc: 0.5597 - val_mean_squared_logarithmic_error: 0.1211\n"
     ]
    }
   ],
   "source": [
    "train_feed = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=20, width_shift_range=0.2,\n",
    "    height_shift_range=0.2, preprocessing_function=tf.keras.applications.xception.preprocess_input)\n",
    "train_iter = train_feed.flow_from_directory(\n",
    "    './DIS/train/', target_size=(299, 299), follow_links=True, class_mode='binary')\n",
    "valid_feed = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=0, width_shift_range=0,\n",
    "    height_shift_range=0, preprocessing_function=tf.keras.applications.xception.preprocess_input)\n",
    "valid_iter = valid_feed.flow_from_directory(\n",
    "    './DIS/valid/', target_size=(299, 299), follow_links=True, class_mode='binary')\n",
    "\n",
    "xcpt_model = tf.keras.applications.Xception(include_top=False, weights='imagenet', input_shape=(299, 299, 3), \n",
    "                                              classes=1)\n",
    "\n",
    "x = xcpt_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(682, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(rate=0.3)(x)\n",
    "predictions = tf.keras.layers.Dense(1, 'sigmoid', bias_initializer='Zeros', \n",
    "                          kernel_initializer=tf.keras.initializers.glorot_uniform(),\n",
    "                          trainable=True, use_bias=True, name='predictions')(x)\n",
    "CNN = tf.keras.models.Model(inputs=xcpt_model.inputs, outputs=predictions)\n",
    "\n",
    "for layer in CNN.layers[:len(xcpt_model.layers)]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "CNN.compile(loss = tf.keras.losses.binary_crossentropy, \n",
    "                    optimizer = tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9),\n",
    "                    metrics=[\"acc\", tf.keras.metrics.mean_squared_logarithmic_error])\n",
    "\n",
    "top_weights_path = '/home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5'\n",
    "callbacks_list = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(top_weights_path, monitor='acc',\n",
    "                                       verbose=1, save_best_only=True),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='acc', patience=10, verbose=1)\n",
    "]\n",
    "\n",
    "train_top = CNN.fit_generator(train_iter, validation_data=valid_iter,\n",
    "                        callbacks=callbacks_list, steps_per_epoch=train_iter.samples//train_iter.batch_size,\n",
    "                        validation_steps=5, shuffle=True, use_multiprocessing=True, workers=1, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 135 images belonging to 2 classes.\n",
      "Found 70 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "3/4 [=====================>........] - ETA: 1s - loss: 0.7759 - acc: 0.4479 - mean_squared_logarithmic_error: 0.1552Epoch 00000: acc improved from -inf to 0.42969, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 24s - loss: 0.7908 - acc: 0.4297 - mean_squared_logarithmic_error: 0.1597 - val_loss: 0.8023 - val_acc: 0.4030 - val_mean_squared_logarithmic_error: 0.1646\n",
      "Epoch 2/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7469 - acc: 0.5298 - mean_squared_logarithmic_error: 0.1418Epoch 00001: acc improved from 0.42969 to 0.44660, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 6s - loss: 0.7699 - acc: 0.4884 - mean_squared_logarithmic_error: 0.1501 - val_loss: 0.7984 - val_acc: 0.4030 - val_mean_squared_logarithmic_error: 0.1637\n",
      "Epoch 3/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7480 - acc: 0.4658 - mean_squared_logarithmic_error: 0.1477Epoch 00002: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.7764 - acc: 0.4356 - mean_squared_logarithmic_error: 0.1558 - val_loss: 0.8026 - val_acc: 0.3955 - val_mean_squared_logarithmic_error: 0.1651\n",
      "Epoch 4/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7406 - acc: 0.5030 - mean_squared_logarithmic_error: 0.1420Epoch 00003: acc improved from 0.44660 to 0.45631, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 6s - loss: 0.7522 - acc: 0.4743 - mean_squared_logarithmic_error: 0.1468 - val_loss: 0.8017 - val_acc: 0.3881 - val_mean_squared_logarithmic_error: 0.1654\n",
      "Epoch 5/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7593 - acc: 0.4375 - mean_squared_logarithmic_error: 0.1516Epoch 00004: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.7250 - acc: 0.4966 - mean_squared_logarithmic_error: 0.1394 - val_loss: 0.7875 - val_acc: 0.4104 - val_mean_squared_logarithmic_error: 0.1603\n",
      "Epoch 6/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7187 - acc: 0.4792 - mean_squared_logarithmic_error: 0.1401Epoch 00005: acc improved from 0.45631 to 0.47656, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 6s - loss: 0.7233 - acc: 0.4766 - mean_squared_logarithmic_error: 0.1416 - val_loss: 0.7875 - val_acc: 0.4030 - val_mean_squared_logarithmic_error: 0.1607\n",
      "Epoch 7/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8150 - acc: 0.3080 - mean_squared_logarithmic_error: 0.1728Epoch 00006: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.7916 - acc: 0.3254 - mean_squared_logarithmic_error: 0.1655 - val_loss: 0.7900 - val_acc: 0.3881 - val_mean_squared_logarithmic_error: 0.1623\n",
      "Epoch 8/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6606 - acc: 0.5595 - mean_squared_logarithmic_error: 0.1187Epoch 00007: acc improved from 0.47656 to 0.50485, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 6s - loss: 0.6921 - acc: 0.4929 - mean_squared_logarithmic_error: 0.1303 - val_loss: 0.7796 - val_acc: 0.4030 - val_mean_squared_logarithmic_error: 0.1586\n",
      "Epoch 9/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7263 - acc: 0.4241 - mean_squared_logarithmic_error: 0.1436Epoch 00008: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.7122 - acc: 0.4438 - mean_squared_logarithmic_error: 0.1388 - val_loss: 0.7818 - val_acc: 0.3881 - val_mean_squared_logarithmic_error: 0.1602\n",
      "Epoch 10/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7197 - acc: 0.4688 - mean_squared_logarithmic_error: 0.1401Epoch 00009: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.7374 - acc: 0.3991 - mean_squared_logarithmic_error: 0.1465 - val_loss: 0.7665 - val_acc: 0.4104 - val_mean_squared_logarithmic_error: 0.1548\n",
      "Epoch 11/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7223 - acc: 0.4688 - mean_squared_logarithmic_error: 0.1415Epoch 00010: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.7162 - acc: 0.4844 - mean_squared_logarithmic_error: 0.1377 - val_loss: 0.7666 - val_acc: 0.4030 - val_mean_squared_logarithmic_error: 0.1552\n",
      "Epoch 12/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6826 - acc: 0.5759 - mean_squared_logarithmic_error: 0.1280Epoch 00011: acc improved from 0.50485 to 0.55340, saving model to /home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5\n",
      "4/4 [==============================] - 6s - loss: 0.6811 - acc: 0.5562 - mean_squared_logarithmic_error: 0.1275 - val_loss: 0.7699 - val_acc: 0.3881 - val_mean_squared_logarithmic_error: 0.1570\n",
      "Epoch 13/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7637 - acc: 0.3080 - mean_squared_logarithmic_error: 0.1610Epoch 00012: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.7470 - acc: 0.3582 - mean_squared_logarithmic_error: 0.1528 - val_loss: 0.7610 - val_acc: 0.3955 - val_mean_squared_logarithmic_error: 0.1542\n",
      "Epoch 14/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7005 - acc: 0.5610 - mean_squared_logarithmic_error: 0.1243Epoch 00013: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.7020 - acc: 0.5622 - mean_squared_logarithmic_error: 0.1258 - val_loss: 0.7536 - val_acc: 0.4104 - val_mean_squared_logarithmic_error: 0.1511\n",
      "Epoch 15/15\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7043 - acc: 0.4792 - mean_squared_logarithmic_error: 0.1364Epoch 00014: acc did not improve\n",
      "4/4 [==============================] - 5s - loss: 0.6922 - acc: 0.5294 - mean_squared_logarithmic_error: 0.1311 - val_loss: 0.7523 - val_acc: 0.4104 - val_mean_squared_logarithmic_error: 0.1506\n"
     ]
    }
   ],
   "source": [
    "train_feed = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=20, width_shift_range=0.2,\n",
    "    height_shift_range=0.2, preprocessing_function=tf.keras.applications.xception.preprocess_input)\n",
    "train_iter = train_feed.flow_from_directory(\n",
    "    './FEA/train/', target_size=(299, 299), follow_links=True, class_mode='binary')\n",
    "valid_feed = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=0, width_shift_range=0,\n",
    "    height_shift_range=0, preprocessing_function=tf.keras.applications.xception.preprocess_input)\n",
    "valid_iter = valid_feed.flow_from_directory(\n",
    "    './FEA/valid/', target_size=(299, 299), follow_links=True, class_mode='binary')\n",
    "\n",
    "xcpt_model = tf.keras.applications.Xception(include_top=False, weights='imagenet', input_shape=(299, 299, 3), \n",
    "                                              classes=1)\n",
    "\n",
    "x = xcpt_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(682, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(rate=0.3)(x)\n",
    "predictions = tf.keras.layers.Dense(1, 'sigmoid', bias_initializer='Zeros', \n",
    "                          kernel_initializer=tf.keras.initializers.glorot_uniform(),\n",
    "                          trainable=True, use_bias=True, name='predictions')(x)\n",
    "CNN = tf.keras.models.Model(inputs=xcpt_model.inputs, outputs=predictions)\n",
    "\n",
    "for layer in CNN.layers[:len(xcpt_model.layers)]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "CNN.compile(loss = tf.keras.losses.binary_crossentropy, \n",
    "                    optimizer = tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9),\n",
    "                    metrics=[\"acc\", tf.keras.metrics.mean_squared_logarithmic_error])\n",
    "\n",
    "top_weights_path = '/home/ubuntu/JapaneseFaces/jaffe/jpg/vision_top_model_weights.h5'\n",
    "callbacks_list = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(top_weights_path, monitor='acc',\n",
    "                                       verbose=1, save_best_only=True),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='acc', patience=10, verbose=1)\n",
    "]\n",
    "\n",
    "train_top = CNN.fit_generator(train_iter, validation_data=valid_iter,\n",
    "                        callbacks=callbacks_list, steps_per_epoch=train_iter.samples//train_iter.batch_size,\n",
    "                        validation_steps=5, shuffle=True, use_multiprocessing=True, workers=1, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ANG</th>\n",
       "      <th>Conf</th>\n",
       "      <th>HAP</th>\n",
       "      <th>PIC</th>\n",
       "      <th>SAD</th>\n",
       "      <th>SUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.901068</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NM-FE3.jpeg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.968047</td>\n",
       "      <td>1.0</td>\n",
       "      <td>YM-NE1.jpeg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>YM-NE2.jpeg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KL-FE2.jpeg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.968292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NM-AN3.jpeg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ANG      Conf  HAP          PIC  SAD  SUR\n",
       "0           0  1.0  0.901068  1.0  NM-FE3.jpeg  3.0  1.0\n",
       "1           1  1.0  0.968047  1.0  YM-NE1.jpeg  2.0  1.0\n",
       "2           2  1.0  0.952909  1.0  YM-NE2.jpeg  2.0  1.0\n",
       "3           3  1.0  0.972460  1.0  KL-FE2.jpeg  4.0  1.0\n",
       "4           4  1.0  0.968292  1.0  NM-AN3.jpeg  3.0  1.0"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GoogleAnalysis = pd.read_csv('../../GoogleAnalysis.csv', sep=',')\n",
    "GoogleAnalysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(GoogleAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>HAP</th>\n",
       "      <th>SAD</th>\n",
       "      <th>SUR</th>\n",
       "      <th>ANG</th>\n",
       "      <th>DIS</th>\n",
       "      <th>FEA</th>\n",
       "      <th>PIC</th>\n",
       "      <th>jpeg_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.87</td>\n",
       "      <td>2.52</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.97</td>\n",
       "      <td>2.06</td>\n",
       "      <td>KM-NE1</td>\n",
       "      <td>KM-NE1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.87</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.77</td>\n",
       "      <td>KM-NE2</td>\n",
       "      <td>KM-NE2.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.73</td>\n",
       "      <td>1.53</td>\n",
       "      <td>KM-NE3</td>\n",
       "      <td>KM-NE3.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.90</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.10</td>\n",
       "      <td>KM-HA1</td>\n",
       "      <td>KM-HA1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4.87</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.07</td>\n",
       "      <td>KM-HA2</td>\n",
       "      <td>KM-HA2.jpeg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #   HAP   SAD   SUR   ANG   DIS   FEA     PIC   jpeg_names\n",
       "0  1  2.87  2.52  2.10  1.97  1.97  2.06  KM-NE1  KM-NE1.jpeg\n",
       "1  2  2.87  2.42  1.58  1.84  1.77  1.77  KM-NE2  KM-NE2.jpeg\n",
       "2  3  2.50  2.10  1.70  1.50  1.73  1.53  KM-NE3  KM-NE3.jpeg\n",
       "3  4  4.90  1.13  1.26  1.10  1.03  1.10  KM-HA1  KM-HA1.jpeg\n",
       "4  5  4.87  1.20  1.43  1.03  1.07  1.07  KM-HA2  KM-HA2.jpeg"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_clean_up(df, directory):\n",
    "    lst = df['PIC']\n",
    "    for row, name in enumerate(lst):\n",
    "        if name not in os.listdir(directory):\n",
    "            print(name)\n",
    "            df.drop(row, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/JapaneseFaces/jaffe/jpg'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ANG</th>\n",
       "      <th>Conf</th>\n",
       "      <th>HAP</th>\n",
       "      <th>PIC</th>\n",
       "      <th>SAD</th>\n",
       "      <th>SUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.901068</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NM-FE3.jpeg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.968047</td>\n",
       "      <td>1.0</td>\n",
       "      <td>YM-NE1.jpeg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>YM-NE2.jpeg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KL-FE2.jpeg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.968292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NM-AN3.jpeg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ANG      Conf  HAP          PIC  SAD  SUR\n",
       "0           0  1.0  0.901068  1.0  NM-FE3.jpeg  3.0  1.0\n",
       "1           1  1.0  0.968047  1.0  YM-NE1.jpeg  2.0  1.0\n",
       "2           2  1.0  0.952909  1.0  YM-NE2.jpeg  2.0  1.0\n",
       "3           3  1.0  0.972460  1.0  KL-FE2.jpeg  4.0  1.0\n",
       "4           4  1.0  0.968292  1.0  NM-AN3.jpeg  3.0  1.0"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_up(GoogleAnalysis, '/home/ubuntu/JapaneseFaces/jaffe/jpg')\n",
    "GoogleAnalysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(GoogleAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_direct('Google/HAP')\n",
    "create_direct('Google/SAD')\n",
    "create_direct('Google/SUR')\n",
    "create_direct('Google/ANG')\n",
    "create_direct('Google/DIS')\n",
    "create_direct('Google/FEA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = []\n",
    "for fold_idx, split in enumerate(folder.split(X=df_inc.index.values)):\n",
    "    folds.append(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ANG</th>\n",
       "      <th>Conf</th>\n",
       "      <th>HAP</th>\n",
       "      <th>SAD</th>\n",
       "      <th>SUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>213.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>213.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>106.000000</td>\n",
       "      <td>1.018779</td>\n",
       "      <td>0.957889</td>\n",
       "      <td>1.460094</td>\n",
       "      <td>2.985915</td>\n",
       "      <td>1.300469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>61.631972</td>\n",
       "      <td>0.136065</td>\n",
       "      <td>0.036751</td>\n",
       "      <td>1.222646</td>\n",
       "      <td>1.606235</td>\n",
       "      <td>0.973154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.758655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>106.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968932</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>159.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979585</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>212.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.996873</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0         ANG        Conf         HAP         SAD         SUR\n",
       "count  213.000000  213.000000  213.000000  213.000000  213.000000  213.000000\n",
       "mean   106.000000    1.018779    0.957889    1.460094    2.985915    1.300469\n",
       "std     61.631972    0.136065    0.036751    1.222646    1.606235    0.973154\n",
       "min      0.000000    1.000000    0.758655    1.000000    1.000000    1.000000\n",
       "25%     53.000000    1.000000    0.951040    1.000000    1.000000    1.000000\n",
       "50%    106.000000    1.000000    0.968932    1.000000    3.000000    1.000000\n",
       "75%    159.000000    1.000000    0.979585    1.000000    5.000000    1.000000\n",
       "max    212.000000    2.000000    0.996873    5.000000    5.000000    5.000000"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GoogleAnalysis.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.460093896713615"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GoogleAnalysis.describe().HAP[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:27: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Google/HAP'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2524\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Google/HAP'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-247-211af023c435>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcl_run_k_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Google/HAP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGoogleAnalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHAP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-176-bd3d73535d41>\u001b[0m in \u001b[0;36mcl_run_k_fold\u001b[0;34m(k, cl, threshold)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'./{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_inc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mtrain_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mtrain_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mvalid_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_inc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1842\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3842\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3843\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3844\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3845\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2525\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Google/HAP'"
     ]
    }
   ],
   "source": [
    "cl_run_k_fold(0, 'Google/HAP', GoogleAnalysis.describe().HAP[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV notes and Fine Tunning\n",
    "So... talked to Matt. We cross validate our entire model, to prove that it is learning. But, and I knew this somewhere in my head, with out a massive data set, you should not train the bottom. Plus, and the more I think about this, the clearer it becomes, we do not have the memory to train a whole network. Moral of the story is, for this toy set, we should not train the whole network. But for the huge PITA dataset, we could think about it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.preprocessing.image.load_img('../Affect')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
